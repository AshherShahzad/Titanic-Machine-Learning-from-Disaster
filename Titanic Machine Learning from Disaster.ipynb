{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys #access to system parameters https://docs.python.org/3/library/sys.html\n",
    "import pandas as pd #collection of functions for data processing and analysis modeled after R dataframes with SQL like features\n",
    "import matplotlib #collection of functions for scientific and publication-ready visualization\n",
    "import numpy as np #foundational package for scientific computing\n",
    "import scipy as sp #collection of functions for scientific computing and advance mathematics\n",
    "import IPython \n",
    "from IPython import display #pretty printing of dataframes in Jupyter notebook\n",
    "import sklearn #collection of machine learning algorithms\n",
    "\n",
    "#misc libraries\n",
    "import random\n",
    "import time\n",
    "\n",
    "\n",
    "#ignore warnings\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Common Model Algorithms\n",
    "from sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\n",
    "#from xgboost import XGBClassifier\n",
    "\n",
    "#Common Model Helpers\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, LabelBinarizer\n",
    "from sklearn import feature_selection\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "\n",
    "#Visualization\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "import seaborn as sns\n",
    "#from pandas.tools.plotting import scatter_matrix\n",
    "\n",
    "#Configure Visualization Defaults\n",
    "#%matplotlib inline = show plots in Jupyter Notebook browser\n",
    "%matplotlib inline\n",
    "mpl.style.use('ggplot')\n",
    "sns.set_style('white')\n",
    "pylab.rcParams['figure.figsize'] = 12,8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier , GradientBoostingClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron, RidgeClassifier, SGDClassifier\n",
    "# model tuning\n",
    "#from hyperopt import STATUS_OK, Trials, fmin, hp, tpe, space_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data Modelling Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "data_raw = pd.read_csv('input/train.csv')\n",
    "data_val  = pd.read_csv('input/test.csv')\n",
    "data1 = data_raw.copy(deep = True)\n",
    "#however passing by reference is convenient, because we can clean both datasets at once\n",
    "data_cleaner = [data1, data_val]\n",
    "#preview data\n",
    "print (data_raw.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The 4 C's of Data Cleaning: Correcting, Completing, Creating, and Converting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train columns with null values:\n",
      " PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n",
      "----------\n",
      "Test/Validation columns with null values:\n",
      " PassengerId      0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age             86\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             1\n",
      "Cabin          327\n",
      "Embarked         0\n",
      "dtype: int64\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>204</td>\n",
       "      <td>889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>891</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>681</td>\n",
       "      <td>NaN</td>\n",
       "      <td>147</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jalsevac, Mr. Ivan</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>577</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.204208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.693429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.910400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PassengerId    Survived      Pclass                Name   Sex  \\\n",
       "count    891.000000  891.000000  891.000000                 891   891   \n",
       "unique          NaN         NaN         NaN                 891     2   \n",
       "top             NaN         NaN         NaN  Jalsevac, Mr. Ivan  male   \n",
       "freq            NaN         NaN         NaN                   1   577   \n",
       "mean     446.000000    0.383838    2.308642                 NaN   NaN   \n",
       "std      257.353842    0.486592    0.836071                 NaN   NaN   \n",
       "min        1.000000    0.000000    1.000000                 NaN   NaN   \n",
       "25%      223.500000    0.000000    2.000000                 NaN   NaN   \n",
       "50%      446.000000    0.000000    3.000000                 NaN   NaN   \n",
       "75%      668.500000    1.000000    3.000000                 NaN   NaN   \n",
       "max      891.000000    1.000000    3.000000                 NaN   NaN   \n",
       "\n",
       "               Age       SibSp       Parch    Ticket        Fare        Cabin  \\\n",
       "count   714.000000  891.000000  891.000000       891  891.000000          204   \n",
       "unique         NaN         NaN         NaN       681         NaN          147   \n",
       "top            NaN         NaN         NaN  CA. 2343         NaN  C23 C25 C27   \n",
       "freq           NaN         NaN         NaN         7         NaN            4   \n",
       "mean     29.699118    0.523008    0.381594       NaN   32.204208          NaN   \n",
       "std      14.526497    1.102743    0.806057       NaN   49.693429          NaN   \n",
       "min       0.420000    0.000000    0.000000       NaN    0.000000          NaN   \n",
       "25%      20.125000    0.000000    0.000000       NaN    7.910400          NaN   \n",
       "50%      28.000000    0.000000    0.000000       NaN   14.454200          NaN   \n",
       "75%      38.000000    1.000000    0.000000       NaN   31.000000          NaN   \n",
       "max      80.000000    8.000000    6.000000       NaN  512.329200          NaN   \n",
       "\n",
       "       Embarked  \n",
       "count       889  \n",
       "unique        3  \n",
       "top           S  \n",
       "freq        644  \n",
       "mean        NaN  \n",
       "std         NaN  \n",
       "min         NaN  \n",
       "25%         NaN  \n",
       "50%         NaN  \n",
       "75%         NaN  \n",
       "max         NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Train columns with null values:\\n', data1.isnull().sum())\n",
    "print(\"-\"*10)\n",
    "\n",
    "print('Test/Validation columns with null values:\\n', data_val.isnull().sum())\n",
    "print(\"-\"*10)\n",
    "\n",
    "data_raw.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean data\n",
    "\n",
    "for dataset in data_cleaner:    \n",
    "    #complete missing age with median\n",
    "    dataset['Age'].fillna(dataset['Age'].median(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#complete embarked with mode\n",
    "dataset['Embarked'].fillna(dataset['Embarked'].mode()[0], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #complete missing fare with median\n",
    "    dataset['Fare'].fillna(dataset['Fare'].median(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete the cabin feature/column and others previously stated to exclude in train dataset\n",
    "drop_column = ['PassengerId','Cabin', 'Ticket']\n",
    "data1.drop(drop_column, axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived    0\n",
      "Pclass      0\n",
      "Name        0\n",
      "Sex         0\n",
      "Age         0\n",
      "SibSp       0\n",
      "Parch       0\n",
      "Fare        0\n",
      "Embarked    2\n",
      "dtype: int64\n",
      "----------\n",
      "PassengerId      0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age              0\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          327\n",
      "Embarked         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data1.isnull().sum())\n",
    "print(\"-\"*10)\n",
    "print(data_val.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1['Embarked'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#complete embarked with mode\n",
    "data1['Embarked'].fillna(data1['Embarked'].mode()[0], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived    0\n",
      "Pclass      0\n",
      "Name        0\n",
      "Sex         0\n",
      "Age         0\n",
      "SibSp       0\n",
      "Parch       0\n",
      "Fare        0\n",
      "Embarked    0\n",
      "dtype: int64\n",
      "----------\n",
      "PassengerId      0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age              0\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          327\n",
      "Embarked         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data1.isnull().sum())\n",
    "print(\"-\"*10)\n",
    "print(data_val.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda\\lib\\site-packages\\pandas\\core\\indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "C:\\Program Files\\Anaconda\\lib\\site-packages\\pandas\\core\\indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "###CREATE: Feature Engineering for train and test/validation dataset\n",
    "for dataset in data_cleaner:    \n",
    "    #Discrete variables\n",
    "    dataset['FamilySize'] = dataset ['SibSp'] + dataset['Parch'] + 1\n",
    "\n",
    "    dataset['IsAlone'] = 1 #initialize to yes/1 is alone\n",
    "    dataset['IsAlone'].loc[dataset['FamilySize'] > 1] = 0 # now update to no/0 if family size is greater than 1\n",
    "\n",
    "    #quick and dirty code split title from name: http://www.pythonforbeginners.com/dictionary/python-split\n",
    "    dataset['Title'] = dataset['Name'].str.split(\", \", expand=True)[1].str.split(\".\", expand=True)[0]\n",
    "\n",
    "\n",
    "    #Continuous variable bins; qcut vs cut: https://stackoverflow.com/questions/30211923/what-is-the-difference-between-pandas-qcut-and-pandas-cut\n",
    "    #Fare Bins/Buckets using qcut or frequency bins: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.qcut.html\n",
    "    dataset['FareBin'] = pd.qcut(dataset['Fare'], 4)\n",
    "\n",
    "    #Age Bins/Buckets using cut or value bins: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.cut.html\n",
    "    dataset['AgeBin'] = pd.cut(dataset['Age'].astype(int), 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr        517\n",
      "Miss      182\n",
      "Mrs       125\n",
      "Master     40\n",
      "Misc       27\n",
      "Name: Title, dtype: int64\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "#cleanup rare title names\n",
    "#print(data1['Title'].value_counts())\n",
    "stat_min = 10 #while small is arbitrary, we'll use the common minimum in statistics: http://nicholasjjackson.com/2012/03/08/sample-size-is-10-a-magic-number/\n",
    "title_names = (data1['Title'].value_counts() < stat_min) #this will create a true false series with title name as index\n",
    "\n",
    "#apply and lambda functions are quick and dirty code to find and replace with fewer lines of code: https://community.modeanalytics.com/python/tutorial/pandas-groupby-and-python-lambda-functions/\n",
    "data1['Title'] = data1['Title'].apply(lambda x: 'Misc' if title_names.loc[x] == True else x)\n",
    "print(data1['Title'].value_counts())\n",
    "print(\"-\"*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 14 columns):\n",
      "Survived      891 non-null int64\n",
      "Pclass        891 non-null int64\n",
      "Name          891 non-null object\n",
      "Sex           891 non-null object\n",
      "Age           891 non-null float64\n",
      "SibSp         891 non-null int64\n",
      "Parch         891 non-null int64\n",
      "Fare          891 non-null float64\n",
      "Embarked      891 non-null object\n",
      "FamilySize    891 non-null int64\n",
      "IsAlone       891 non-null int64\n",
      "Title         891 non-null object\n",
      "FareBin       891 non-null category\n",
      "AgeBin        891 non-null category\n",
      "dtypes: category(2), float64(2), int64(6), object(4)\n",
      "memory usage: 85.5+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 16 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Pclass         418 non-null int64\n",
      "Name           418 non-null object\n",
      "Sex            418 non-null object\n",
      "Age            418 non-null float64\n",
      "SibSp          418 non-null int64\n",
      "Parch          418 non-null int64\n",
      "Ticket         418 non-null object\n",
      "Fare           418 non-null float64\n",
      "Cabin          91 non-null object\n",
      "Embarked       418 non-null object\n",
      "FamilySize     418 non-null int64\n",
      "IsAlone        418 non-null int64\n",
      "Title          418 non-null object\n",
      "FareBin        418 non-null category\n",
      "AgeBin         418 non-null category\n",
      "dtypes: category(2), float64(2), int64(6), object(6)\n",
      "memory usage: 46.8+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>Title</th>\n",
       "      <th>FareBin</th>\n",
       "      <th>AgeBin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Nicola-Yarred, Master. Elias</td>\n",
       "      <td>male</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.2417</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Master</td>\n",
       "      <td>(7.91, 14.454]</td>\n",
       "      <td>(-0.08, 16.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Oreskovic, Miss. Marija</td>\n",
       "      <td>female</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Miss</td>\n",
       "      <td>(7.91, 14.454]</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Pavlovic, Mr. Stefo</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr</td>\n",
       "      <td>(-0.001, 7.91]</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Frauenthal, Dr. Henry William</td>\n",
       "      <td>male</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>133.6500</td>\n",
       "      <td>S</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Misc</td>\n",
       "      <td>(31.0, 512.329]</td>\n",
       "      <td>(48.0, 64.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Smart, Mr. John Montgomery</td>\n",
       "      <td>male</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr</td>\n",
       "      <td>(14.454, 31.0]</td>\n",
       "      <td>(48.0, 64.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Isham, Miss. Ann Elizabeth</td>\n",
       "      <td>female</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.7125</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Miss</td>\n",
       "      <td>(14.454, 31.0]</td>\n",
       "      <td>(48.0, 64.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Watson, Mr. Ennis Hastings</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr</td>\n",
       "      <td>(-0.001, 7.91]</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>Q</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr</td>\n",
       "      <td>(7.91, 14.454]</td>\n",
       "      <td>(16.0, 32.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Byles, Rev. Thomas Roussel Davids</td>\n",
       "      <td>male</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Misc</td>\n",
       "      <td>(7.91, 14.454]</td>\n",
       "      <td>(32.0, 48.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Stone, Mrs. George Nelson (Martha Evelyn)</td>\n",
       "      <td>female</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>(31.0, 512.329]</td>\n",
       "      <td>(48.0, 64.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass                                       Name     Sex  \\\n",
       "125         1       3               Nicola-Yarred, Master. Elias    male   \n",
       "404         0       3                    Oreskovic, Miss. Marija  female   \n",
       "519         0       3                        Pavlovic, Mr. Stefo    male   \n",
       "660         1       1              Frauenthal, Dr. Henry William    male   \n",
       "467         0       1                 Smart, Mr. John Montgomery    male   \n",
       "177         0       1                 Isham, Miss. Ann Elizabeth  female   \n",
       "674         0       2                 Watson, Mr. Ennis Hastings    male   \n",
       "5           0       3                           Moran, Mr. James    male   \n",
       "149         0       2          Byles, Rev. Thomas Roussel Davids    male   \n",
       "829         1       1  Stone, Mrs. George Nelson (Martha Evelyn)  female   \n",
       "\n",
       "      Age  SibSp  Parch      Fare Embarked  FamilySize  IsAlone   Title  \\\n",
       "125  12.0      1      0   11.2417        C           2        0  Master   \n",
       "404  20.0      0      0    8.6625        S           1        1    Miss   \n",
       "519  32.0      0      0    7.8958        S           1        1      Mr   \n",
       "660  50.0      2      0  133.6500        S           3        0    Misc   \n",
       "467  56.0      0      0   26.5500        S           1        1      Mr   \n",
       "177  50.0      0      0   28.7125        C           1        1    Miss   \n",
       "674  28.0      0      0    0.0000        S           1        1      Mr   \n",
       "5    28.0      0      0    8.4583        Q           1        1      Mr   \n",
       "149  42.0      0      0   13.0000        S           1        1    Misc   \n",
       "829  62.0      0      0   80.0000        S           1        1     Mrs   \n",
       "\n",
       "             FareBin         AgeBin  \n",
       "125   (7.91, 14.454]  (-0.08, 16.0]  \n",
       "404   (7.91, 14.454]   (16.0, 32.0]  \n",
       "519   (-0.001, 7.91]   (16.0, 32.0]  \n",
       "660  (31.0, 512.329]   (48.0, 64.0]  \n",
       "467   (14.454, 31.0]   (48.0, 64.0]  \n",
       "177   (14.454, 31.0]   (48.0, 64.0]  \n",
       "674   (-0.001, 7.91]   (16.0, 32.0]  \n",
       "5     (7.91, 14.454]   (16.0, 32.0]  \n",
       "149   (7.91, 14.454]   (32.0, 48.0]  \n",
       "829  (31.0, 512.329]   (48.0, 64.0]  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preview data again\n",
    "data1.info()\n",
    "data_val.info()\n",
    "data1.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Convert Formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code categorical data\n",
    "label = LabelEncoder()\n",
    "for dataset in data_cleaner:    \n",
    "    dataset['Sex_Code'] = label.fit_transform(dataset['Sex'])\n",
    "    dataset['Embarked_Code'] = label.fit_transform(dataset['Embarked'])\n",
    "    dataset['Title_Code'] = label.fit_transform(dataset['Title'])\n",
    "    dataset['AgeBin_Code'] = label.fit_transform(dataset['AgeBin'])\n",
    "    dataset['FareBin_Code'] = label.fit_transform(dataset['FareBin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define y variable aka target/outcome\n",
    "Target = ['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original X Y:  ['Survived', 'Sex', 'Pclass', 'Embarked', 'Title', 'SibSp', 'Parch', 'Age', 'Fare', 'FamilySize', 'IsAlone'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#define x variables for original features aka feature selection\n",
    "data1_x = ['Sex','Pclass', 'Embarked', 'Title','SibSp', 'Parch', 'Age', 'Fare', 'FamilySize', 'IsAlone'] #pretty name/values for charts\n",
    "data1_x_calc = ['Sex_Code','Pclass', 'Embarked_Code', 'Title_Code','SibSp', 'Parch', 'Age', 'Fare'] #coded for algorithm calculation\n",
    "data1_xy =  Target + data1_x\n",
    "print('Original X Y: ', data1_xy, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bin X Y:  ['Survived', 'Sex_Code', 'Pclass', 'Embarked_Code', 'Title_Code', 'FamilySize', 'AgeBin_Code', 'FareBin_Code'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#define x variables for original w/bin features to remove continuous variables\n",
    "data1_x_bin = ['Sex_Code','Pclass', 'Embarked_Code', 'Title_Code', 'FamilySize', 'AgeBin_Code', 'FareBin_Code']\n",
    "data1_xy_bin = Target + data1_x_bin\n",
    "print('Bin X Y: ', data1_xy_bin, '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy X Y:  ['Survived', 'Pclass', 'SibSp', 'Parch', 'Age', 'Fare', 'FamilySize', 'IsAlone', 'Sex_female', 'Sex_male', 'Embarked_C', 'Embarked_Q', 'Embarked_S', 'Title_Master', 'Title_Misc', 'Title_Miss', 'Title_Mr', 'Title_Mrs'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#define x and y variables for dummy features original\n",
    "data1_dummy = pd.get_dummies(data1[data1_x])\n",
    "data1_x_dummy = data1_dummy.columns.tolist()\n",
    "data1_xy_dummy = Target + data1_x_dummy\n",
    "print('Dummy X Y: ', data1_xy_dummy, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Misc</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  SibSp  Parch   Age     Fare  FamilySize  IsAlone  Sex_female  \\\n",
       "0       3      1      0  22.0   7.2500           2        0           0   \n",
       "1       1      1      0  38.0  71.2833           2        0           1   \n",
       "2       3      0      0  26.0   7.9250           1        1           1   \n",
       "3       1      1      0  35.0  53.1000           2        0           1   \n",
       "4       3      0      0  35.0   8.0500           1        1           0   \n",
       "\n",
       "   Sex_male  Embarked_C  Embarked_Q  Embarked_S  Title_Master  Title_Misc  \\\n",
       "0         1           0           0           1             0           0   \n",
       "1         0           1           0           0             0           0   \n",
       "2         0           0           0           1             0           0   \n",
       "3         0           0           0           1             0           0   \n",
       "4         1           0           0           1             0           0   \n",
       "\n",
       "   Title_Miss  Title_Mr  Title_Mrs  \n",
       "0           0         1          0  \n",
       "1           0         0          1  \n",
       "2           1         0          0  \n",
       "3           0         0          1  \n",
       "4           0         1          0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1_dummy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Da-Double Check Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train columns with null values: \n",
      " Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age              0\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Fare             0\n",
      "Embarked         0\n",
      "FamilySize       0\n",
      "IsAlone          0\n",
      "Title            0\n",
      "FareBin          0\n",
      "AgeBin           0\n",
      "Sex_Code         0\n",
      "Embarked_Code    0\n",
      "Title_Code       0\n",
      "AgeBin_Code      0\n",
      "FareBin_Code     0\n",
      "dtype: int64\n",
      "----------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 19 columns):\n",
      "Survived         891 non-null int64\n",
      "Pclass           891 non-null int64\n",
      "Name             891 non-null object\n",
      "Sex              891 non-null object\n",
      "Age              891 non-null float64\n",
      "SibSp            891 non-null int64\n",
      "Parch            891 non-null int64\n",
      "Fare             891 non-null float64\n",
      "Embarked         891 non-null object\n",
      "FamilySize       891 non-null int64\n",
      "IsAlone          891 non-null int64\n",
      "Title            891 non-null object\n",
      "FareBin          891 non-null category\n",
      "AgeBin           891 non-null category\n",
      "Sex_Code         891 non-null int32\n",
      "Embarked_Code    891 non-null int32\n",
      "Title_Code       891 non-null int32\n",
      "AgeBin_Code      891 non-null int32\n",
      "FareBin_Code     891 non-null int32\n",
      "dtypes: category(2), float64(2), int32(5), int64(6), object(4)\n",
      "memory usage: 102.9+ KB\n",
      "None\n",
      "----------\n",
      "Test/Validation columns with null values: \n",
      " PassengerId        0\n",
      "Pclass             0\n",
      "Name               0\n",
      "Sex                0\n",
      "Age                0\n",
      "SibSp              0\n",
      "Parch              0\n",
      "Ticket             0\n",
      "Fare               0\n",
      "Cabin            327\n",
      "Embarked           0\n",
      "FamilySize         0\n",
      "IsAlone            0\n",
      "Title              0\n",
      "FareBin            0\n",
      "AgeBin             0\n",
      "Sex_Code           0\n",
      "Embarked_Code      0\n",
      "Title_Code         0\n",
      "AgeBin_Code        0\n",
      "FareBin_Code       0\n",
      "dtype: int64\n",
      "----------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 21 columns):\n",
      "PassengerId      418 non-null int64\n",
      "Pclass           418 non-null int64\n",
      "Name             418 non-null object\n",
      "Sex              418 non-null object\n",
      "Age              418 non-null float64\n",
      "SibSp            418 non-null int64\n",
      "Parch            418 non-null int64\n",
      "Ticket           418 non-null object\n",
      "Fare             418 non-null float64\n",
      "Cabin            91 non-null object\n",
      "Embarked         418 non-null object\n",
      "FamilySize       418 non-null int64\n",
      "IsAlone          418 non-null int64\n",
      "Title            418 non-null object\n",
      "FareBin          418 non-null category\n",
      "AgeBin           418 non-null category\n",
      "Sex_Code         418 non-null int32\n",
      "Embarked_Code    418 non-null int32\n",
      "Title_Code       418 non-null int32\n",
      "AgeBin_Code      418 non-null int32\n",
      "FareBin_Code     418 non-null int32\n",
      "dtypes: category(2), float64(2), int32(5), int64(6), object(6)\n",
      "memory usage: 54.9+ KB\n",
      "None\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>204</td>\n",
       "      <td>889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>891</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>681</td>\n",
       "      <td>NaN</td>\n",
       "      <td>147</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jalsevac, Mr. Ivan</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>577</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.204208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.693429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.910400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PassengerId    Survived      Pclass                Name   Sex  \\\n",
       "count    891.000000  891.000000  891.000000                 891   891   \n",
       "unique          NaN         NaN         NaN                 891     2   \n",
       "top             NaN         NaN         NaN  Jalsevac, Mr. Ivan  male   \n",
       "freq            NaN         NaN         NaN                   1   577   \n",
       "mean     446.000000    0.383838    2.308642                 NaN   NaN   \n",
       "std      257.353842    0.486592    0.836071                 NaN   NaN   \n",
       "min        1.000000    0.000000    1.000000                 NaN   NaN   \n",
       "25%      223.500000    0.000000    2.000000                 NaN   NaN   \n",
       "50%      446.000000    0.000000    3.000000                 NaN   NaN   \n",
       "75%      668.500000    1.000000    3.000000                 NaN   NaN   \n",
       "max      891.000000    1.000000    3.000000                 NaN   NaN   \n",
       "\n",
       "               Age       SibSp       Parch    Ticket        Fare        Cabin  \\\n",
       "count   714.000000  891.000000  891.000000       891  891.000000          204   \n",
       "unique         NaN         NaN         NaN       681         NaN          147   \n",
       "top            NaN         NaN         NaN  CA. 2343         NaN  C23 C25 C27   \n",
       "freq           NaN         NaN         NaN         7         NaN            4   \n",
       "mean     29.699118    0.523008    0.381594       NaN   32.204208          NaN   \n",
       "std      14.526497    1.102743    0.806057       NaN   49.693429          NaN   \n",
       "min       0.420000    0.000000    0.000000       NaN    0.000000          NaN   \n",
       "25%      20.125000    0.000000    0.000000       NaN    7.910400          NaN   \n",
       "50%      28.000000    0.000000    0.000000       NaN   14.454200          NaN   \n",
       "75%      38.000000    1.000000    0.000000       NaN   31.000000          NaN   \n",
       "max      80.000000    8.000000    6.000000       NaN  512.329200          NaN   \n",
       "\n",
       "       Embarked  \n",
       "count       889  \n",
       "unique        3  \n",
       "top           S  \n",
       "freq        644  \n",
       "mean        NaN  \n",
       "std         NaN  \n",
       "min         NaN  \n",
       "25%         NaN  \n",
       "50%         NaN  \n",
       "75%         NaN  \n",
       "max         NaN  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Train columns with null values: \\n', data1.isnull().sum())\n",
    "print(\"-\"*10)\n",
    "print (data1.info())\n",
    "print(\"-\"*10)\n",
    "\n",
    "print('Test/Validation columns with null values: \\n', data_val.isnull().sum())\n",
    "print(\"-\"*10)\n",
    "print (data_val.info())\n",
    "print(\"-\"*10)\n",
    "\n",
    "data_raw.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Training and Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1_x, test1_x, train1_y, test1_y = model_selection.train_test_split(data1[data1_x_calc], data1[Target], random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1_x_bin, test1_x_bin, train1_y_bin, test1_y_bin = model_selection.train_test_split(data1[data1_x_bin], data1[Target] , random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1_x_dummy, test1_x_dummy, train1_y_dummy, test1_y_dummy = model_selection.train_test_split(data1_dummy[data1_x_dummy], data1[Target], random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data1 Shape: (891, 19)\n",
      "Train1 Shape: (668, 8)\n",
      "Test1 Shape: (223, 8)\n"
     ]
    }
   ],
   "source": [
    "print(\"Data1 Shape: {}\".format(data1.shape))\n",
    "print(\"Train1 Shape: {}\".format(train1_x.shape))\n",
    "print(\"Test1 Shape: {}\".format(test1_x.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(200, activation='relu', input_dim=train1_x.shape[1]))\n",
    "    model.add(Dense(200, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(optimizer = 'nadam',#\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    return model\n",
    "# 79% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 200)               1800      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 402       \n",
      "=================================================================\n",
      "Total params: 42,402\n",
      "Trainable params: 42,402\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 500\n",
    "num_batch = 320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "Train on 534 samples, validate on 134 samples\n",
      "Epoch 1/500\n",
      "534/534 - 1s - loss: 1.2403 - acc: 0.5412 - val_loss: 0.6225 - val_acc: 0.6716\n",
      "Epoch 2/500\n",
      "534/534 - 0s - loss: 0.6660 - acc: 0.6629 - val_loss: 0.9325 - val_acc: 0.6418\n",
      "Epoch 3/500\n",
      "534/534 - 0s - loss: 0.8994 - acc: 0.6086 - val_loss: 0.8417 - val_acc: 0.6716\n",
      "Epoch 4/500\n",
      "534/534 - 0s - loss: 0.8587 - acc: 0.5955 - val_loss: 0.9369 - val_acc: 0.6642\n",
      "Epoch 5/500\n",
      "534/534 - 0s - loss: 1.0132 - acc: 0.6142 - val_loss: 0.7264 - val_acc: 0.6866\n",
      "Epoch 6/500\n",
      "534/534 - 0s - loss: 0.7210 - acc: 0.6442 - val_loss: 0.7054 - val_acc: 0.6866\n",
      "Epoch 7/500\n",
      "534/534 - 0s - loss: 0.7298 - acc: 0.6386 - val_loss: 0.7025 - val_acc: 0.6716\n",
      "Epoch 8/500\n",
      "534/534 - 0s - loss: 0.7039 - acc: 0.6554 - val_loss: 0.7492 - val_acc: 0.6866\n",
      "Epoch 9/500\n",
      "534/534 - 0s - loss: 0.6942 - acc: 0.6536 - val_loss: 0.6315 - val_acc: 0.6716\n",
      "Epoch 10/500\n",
      "534/534 - 0s - loss: 0.7397 - acc: 0.6461 - val_loss: 1.0691 - val_acc: 0.4851\n",
      "Epoch 11/500\n",
      "534/534 - 0s - loss: 0.9168 - acc: 0.5431 - val_loss: 0.5950 - val_acc: 0.7015\n",
      "Epoch 12/500\n",
      "534/534 - 0s - loss: 0.5844 - acc: 0.7079 - val_loss: 0.5727 - val_acc: 0.7164\n",
      "Epoch 13/500\n",
      "534/534 - 0s - loss: 0.6266 - acc: 0.6704 - val_loss: 1.0876 - val_acc: 0.5672\n",
      "Epoch 14/500\n",
      "534/534 - 0s - loss: 0.9571 - acc: 0.5712 - val_loss: 0.5992 - val_acc: 0.6567\n",
      "Epoch 15/500\n",
      "534/534 - 0s - loss: 0.5701 - acc: 0.7228 - val_loss: 0.5658 - val_acc: 0.7090\n",
      "Epoch 16/500\n",
      "534/534 - 0s - loss: 0.6149 - acc: 0.6667 - val_loss: 1.0104 - val_acc: 0.6866\n",
      "Epoch 17/500\n",
      "534/534 - 0s - loss: 0.9186 - acc: 0.6311 - val_loss: 0.6251 - val_acc: 0.6866\n",
      "Epoch 18/500\n",
      "534/534 - 0s - loss: 0.6620 - acc: 0.6536 - val_loss: 0.8423 - val_acc: 0.7313\n",
      "Epoch 19/500\n",
      "534/534 - 0s - loss: 0.7205 - acc: 0.6667 - val_loss: 0.6063 - val_acc: 0.6343\n",
      "Epoch 20/500\n",
      "534/534 - 0s - loss: 0.5696 - acc: 0.7322 - val_loss: 0.6528 - val_acc: 0.5821\n",
      "Epoch 21/500\n",
      "534/534 - 0s - loss: 0.7748 - acc: 0.6086 - val_loss: 0.9621 - val_acc: 0.5522\n",
      "Epoch 22/500\n",
      "534/534 - 0s - loss: 0.8253 - acc: 0.6348 - val_loss: 0.7248 - val_acc: 0.6343\n",
      "Epoch 23/500\n",
      "534/534 - 0s - loss: 0.6499 - acc: 0.6779 - val_loss: 0.7677 - val_acc: 0.5522\n",
      "Epoch 24/500\n",
      "534/534 - 0s - loss: 0.8137 - acc: 0.6404 - val_loss: 0.6738 - val_acc: 0.6418\n",
      "Epoch 25/500\n",
      "534/534 - 0s - loss: 0.6434 - acc: 0.7116 - val_loss: 0.8363 - val_acc: 0.5522\n",
      "Epoch 26/500\n",
      "534/534 - 0s - loss: 0.7722 - acc: 0.6142 - val_loss: 0.7374 - val_acc: 0.6567\n",
      "Epoch 27/500\n",
      "534/534 - 0s - loss: 0.6506 - acc: 0.7172 - val_loss: 0.5973 - val_acc: 0.6343\n",
      "Epoch 28/500\n",
      "534/534 - 0s - loss: 0.5478 - acc: 0.7172 - val_loss: 0.5630 - val_acc: 0.6343\n",
      "Epoch 29/500\n",
      "534/534 - 0s - loss: 0.5485 - acc: 0.7210 - val_loss: 0.6467 - val_acc: 0.5746\n",
      "Epoch 30/500\n",
      "534/534 - 0s - loss: 0.6589 - acc: 0.6498 - val_loss: 0.7515 - val_acc: 0.6418\n",
      "Epoch 31/500\n",
      "534/534 - 0s - loss: 0.6437 - acc: 0.7004 - val_loss: 0.6204 - val_acc: 0.6418\n",
      "Epoch 32/500\n",
      "534/534 - 0s - loss: 0.5768 - acc: 0.7341 - val_loss: 0.6763 - val_acc: 0.5672\n",
      "Epoch 33/500\n",
      "534/534 - 0s - loss: 0.6208 - acc: 0.6891 - val_loss: 0.6260 - val_acc: 0.6493\n",
      "Epoch 34/500\n",
      "534/534 - 0s - loss: 0.5744 - acc: 0.7285 - val_loss: 0.6437 - val_acc: 0.5597\n",
      "Epoch 35/500\n",
      "534/534 - 0s - loss: 0.6787 - acc: 0.6779 - val_loss: 0.8532 - val_acc: 0.5522\n",
      "Epoch 36/500\n",
      "534/534 - 0s - loss: 0.7530 - acc: 0.6348 - val_loss: 0.6964 - val_acc: 0.6642\n",
      "Epoch 37/500\n",
      "534/534 - 0s - loss: 0.6415 - acc: 0.7191 - val_loss: 0.7229 - val_acc: 0.5522\n",
      "Epoch 38/500\n",
      "534/534 - 0s - loss: 0.7668 - acc: 0.6180 - val_loss: 0.8215 - val_acc: 0.5522\n",
      "Epoch 39/500\n",
      "534/534 - 0s - loss: 0.6813 - acc: 0.6910 - val_loss: 0.6601 - val_acc: 0.6119\n",
      "Epoch 40/500\n",
      "534/534 - 0s - loss: 0.6210 - acc: 0.7154 - val_loss: 0.8054 - val_acc: 0.5522\n",
      "Epoch 41/500\n",
      "534/534 - 0s - loss: 0.8191 - acc: 0.6292 - val_loss: 0.7630 - val_acc: 0.5522\n",
      "Epoch 42/500\n",
      "534/534 - 0s - loss: 0.7592 - acc: 0.6311 - val_loss: 0.8760 - val_acc: 0.5522\n",
      "Epoch 43/500\n",
      "534/534 - 0s - loss: 0.8000 - acc: 0.6367 - val_loss: 0.7588 - val_acc: 0.5896\n",
      "Epoch 44/500\n",
      "534/534 - 0s - loss: 0.6024 - acc: 0.7079 - val_loss: 0.5488 - val_acc: 0.6642\n",
      "Epoch 45/500\n",
      "534/534 - 0s - loss: 0.5270 - acc: 0.7341 - val_loss: 0.6447 - val_acc: 0.5597\n",
      "Epoch 46/500\n",
      "534/534 - 0s - loss: 0.5981 - acc: 0.6929 - val_loss: 0.6479 - val_acc: 0.5597\n",
      "Epoch 47/500\n",
      "534/534 - 0s - loss: 0.6184 - acc: 0.6816 - val_loss: 0.6769 - val_acc: 0.5597\n",
      "Epoch 48/500\n",
      "534/534 - 0s - loss: 0.5816 - acc: 0.6835 - val_loss: 0.5975 - val_acc: 0.6418\n",
      "Epoch 49/500\n",
      "534/534 - 0s - loss: 0.5311 - acc: 0.7303 - val_loss: 0.5462 - val_acc: 0.6642\n",
      "Epoch 50/500\n",
      "534/534 - 0s - loss: 0.5137 - acc: 0.7584 - val_loss: 0.5678 - val_acc: 0.7313\n",
      "Epoch 51/500\n",
      "534/534 - 0s - loss: 0.6330 - acc: 0.7097 - val_loss: 0.9179 - val_acc: 0.7015\n",
      "Epoch 52/500\n",
      "534/534 - 0s - loss: 0.8197 - acc: 0.6667 - val_loss: 0.5490 - val_acc: 0.6866\n",
      "Epoch 53/500\n",
      "534/534 - 0s - loss: 0.5270 - acc: 0.7434 - val_loss: 0.5400 - val_acc: 0.6642\n",
      "Epoch 54/500\n",
      "534/534 - 0s - loss: 0.5080 - acc: 0.7603 - val_loss: 0.5283 - val_acc: 0.7836\n",
      "Epoch 55/500\n",
      "534/534 - 0s - loss: 0.5884 - acc: 0.6891 - val_loss: 0.8358 - val_acc: 0.7239\n",
      "Epoch 56/500\n",
      "534/534 - 0s - loss: 0.8378 - acc: 0.6536 - val_loss: 0.5441 - val_acc: 0.7388\n",
      "Epoch 57/500\n",
      "534/534 - 0s - loss: 0.6471 - acc: 0.6854 - val_loss: 0.8832 - val_acc: 0.7239\n",
      "Epoch 58/500\n",
      "534/534 - 0s - loss: 0.7815 - acc: 0.6536 - val_loss: 0.5650 - val_acc: 0.6493\n",
      "Epoch 59/500\n",
      "534/534 - 0s - loss: 0.5282 - acc: 0.7453 - val_loss: 0.6433 - val_acc: 0.5672\n",
      "Epoch 60/500\n",
      "534/534 - 0s - loss: 0.6116 - acc: 0.6835 - val_loss: 0.5946 - val_acc: 0.6567\n",
      "Epoch 61/500\n",
      "534/534 - 0s - loss: 0.5434 - acc: 0.7247 - val_loss: 0.5743 - val_acc: 0.7761\n",
      "Epoch 62/500\n",
      "534/534 - 0s - loss: 0.6917 - acc: 0.6873 - val_loss: 0.7321 - val_acc: 0.7537\n",
      "Epoch 63/500\n",
      "534/534 - 0s - loss: 0.8020 - acc: 0.6367 - val_loss: 0.7411 - val_acc: 0.7612\n",
      "Epoch 64/500\n",
      "534/534 - 0s - loss: 0.6626 - acc: 0.7341 - val_loss: 0.5418 - val_acc: 0.6567\n",
      "Epoch 65/500\n",
      "534/534 - 0s - loss: 0.5106 - acc: 0.7453 - val_loss: 0.5530 - val_acc: 0.6418\n",
      "Epoch 66/500\n",
      "534/534 - 0s - loss: 0.5100 - acc: 0.7491 - val_loss: 0.6038 - val_acc: 0.5821\n",
      "Epoch 67/500\n",
      "534/534 - 0s - loss: 0.5546 - acc: 0.7397 - val_loss: 0.5343 - val_acc: 0.6716\n",
      "Epoch 68/500\n",
      "534/534 - 0s - loss: 0.5099 - acc: 0.7341 - val_loss: 0.5648 - val_acc: 0.7836\n",
      "Epoch 69/500\n",
      "534/534 - 0s - loss: 0.5666 - acc: 0.7341 - val_loss: 0.6368 - val_acc: 0.7836\n",
      "Epoch 70/500\n",
      "534/534 - 0s - loss: 0.5980 - acc: 0.7472 - val_loss: 0.5182 - val_acc: 0.7015\n",
      "Epoch 71/500\n",
      "534/534 - 0s - loss: 0.4881 - acc: 0.7678 - val_loss: 0.5646 - val_acc: 0.6418\n",
      "Epoch 72/500\n",
      "534/534 - 0s - loss: 0.5189 - acc: 0.7715 - val_loss: 0.5683 - val_acc: 0.6269\n",
      "Epoch 73/500\n",
      "534/534 - 0s - loss: 0.5483 - acc: 0.7378 - val_loss: 0.7242 - val_acc: 0.5672\n",
      "Epoch 74/500\n",
      "534/534 - 0s - loss: 0.6993 - acc: 0.6348 - val_loss: 0.6519 - val_acc: 0.6642\n",
      "Epoch 75/500\n",
      "534/534 - 0s - loss: 0.5468 - acc: 0.7472 - val_loss: 0.5517 - val_acc: 0.6716\n",
      "Epoch 76/500\n",
      "534/534 - 0s - loss: 0.5344 - acc: 0.7509 - val_loss: 0.8195 - val_acc: 0.5597\n",
      "Epoch 77/500\n",
      "534/534 - 0s - loss: 0.6626 - acc: 0.7060 - val_loss: 0.6307 - val_acc: 0.5970\n",
      "Epoch 78/500\n",
      "534/534 - 0s - loss: 0.5858 - acc: 0.7060 - val_loss: 0.6822 - val_acc: 0.5672\n",
      "Epoch 79/500\n",
      "534/534 - 0s - loss: 0.5945 - acc: 0.6854 - val_loss: 0.5892 - val_acc: 0.6716\n",
      "Epoch 80/500\n",
      "534/534 - 0s - loss: 0.5037 - acc: 0.7622 - val_loss: 0.5118 - val_acc: 0.6866\n",
      "Epoch 81/500\n",
      "534/534 - 0s - loss: 0.4816 - acc: 0.7865 - val_loss: 0.6696 - val_acc: 0.5522\n",
      "Epoch 82/500\n",
      "534/534 - 0s - loss: 0.6100 - acc: 0.6948 - val_loss: 0.6407 - val_acc: 0.6269\n",
      "Epoch 83/500\n",
      "534/534 - 0s - loss: 0.5743 - acc: 0.7266 - val_loss: 0.6716 - val_acc: 0.5821\n",
      "Epoch 84/500\n",
      "534/534 - 0s - loss: 0.5716 - acc: 0.7228 - val_loss: 0.5575 - val_acc: 0.6716\n",
      "Epoch 85/500\n",
      "534/534 - 0s - loss: 0.4961 - acc: 0.7715 - val_loss: 0.5922 - val_acc: 0.6343\n",
      "Epoch 86/500\n",
      "534/534 - 0s - loss: 0.5478 - acc: 0.7528 - val_loss: 0.7141 - val_acc: 0.5821\n",
      "Epoch 87/500\n",
      "534/534 - 0s - loss: 0.6296 - acc: 0.6929 - val_loss: 0.6555 - val_acc: 0.6642\n",
      "Epoch 88/500\n",
      "534/534 - 0s - loss: 0.5428 - acc: 0.7528 - val_loss: 0.5683 - val_acc: 0.6567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/500\n",
      "534/534 - 0s - loss: 0.5335 - acc: 0.7285 - val_loss: 0.7068 - val_acc: 0.5746\n",
      "Epoch 90/500\n",
      "534/534 - 0s - loss: 0.5843 - acc: 0.7060 - val_loss: 0.5502 - val_acc: 0.6493\n",
      "Epoch 91/500\n",
      "534/534 - 0s - loss: 0.5339 - acc: 0.7528 - val_loss: 0.8382 - val_acc: 0.5672\n",
      "Epoch 92/500\n",
      "534/534 - 0s - loss: 0.7299 - acc: 0.6704 - val_loss: 0.6380 - val_acc: 0.6716\n",
      "Epoch 93/500\n",
      "534/534 - 0s - loss: 0.5142 - acc: 0.7697 - val_loss: 0.5105 - val_acc: 0.7239\n",
      "Epoch 94/500\n",
      "534/534 - 0s - loss: 0.4708 - acc: 0.7715 - val_loss: 0.5811 - val_acc: 0.6343\n",
      "Epoch 95/500\n",
      "534/534 - 0s - loss: 0.5258 - acc: 0.7603 - val_loss: 0.6791 - val_acc: 0.5672\n",
      "Epoch 96/500\n",
      "534/534 - 0s - loss: 0.6241 - acc: 0.6854 - val_loss: 0.6154 - val_acc: 0.6642\n",
      "Epoch 97/500\n",
      "534/534 - 0s - loss: 0.4952 - acc: 0.7772 - val_loss: 0.5165 - val_acc: 0.7463\n",
      "Epoch 98/500\n",
      "534/534 - 0s - loss: 0.4791 - acc: 0.8015 - val_loss: 0.6031 - val_acc: 0.6343\n",
      "Epoch 99/500\n",
      "534/534 - 0s - loss: 0.5396 - acc: 0.7528 - val_loss: 0.5680 - val_acc: 0.6493\n",
      "Epoch 100/500\n",
      "534/534 - 0s - loss: 0.4932 - acc: 0.7622 - val_loss: 0.5604 - val_acc: 0.6493\n",
      "Epoch 101/500\n",
      "534/534 - 0s - loss: 0.4968 - acc: 0.7566 - val_loss: 0.5985 - val_acc: 0.6418\n",
      "Epoch 102/500\n",
      "534/534 - 0s - loss: 0.5536 - acc: 0.7509 - val_loss: 0.7295 - val_acc: 0.5821\n",
      "Epoch 103/500\n",
      "534/534 - 0s - loss: 0.5897 - acc: 0.7154 - val_loss: 0.5734 - val_acc: 0.6567\n",
      "Epoch 104/500\n",
      "534/534 - 0s - loss: 0.4913 - acc: 0.7640 - val_loss: 0.5396 - val_acc: 0.7015\n",
      "Epoch 105/500\n",
      "534/534 - 0s - loss: 0.4976 - acc: 0.7640 - val_loss: 0.6367 - val_acc: 0.6418\n",
      "Epoch 106/500\n",
      "534/534 - 0s - loss: 0.5544 - acc: 0.7172 - val_loss: 0.5762 - val_acc: 0.6642\n",
      "Epoch 107/500\n",
      "534/534 - 0s - loss: 0.4775 - acc: 0.7959 - val_loss: 0.4883 - val_acc: 0.7836\n",
      "Epoch 108/500\n",
      "534/534 - 0s - loss: 0.4586 - acc: 0.8202 - val_loss: 0.4945 - val_acc: 0.7985\n",
      "Epoch 109/500\n",
      "534/534 - 0s - loss: 0.4650 - acc: 0.8015 - val_loss: 0.4835 - val_acc: 0.7910\n",
      "Epoch 110/500\n",
      "534/534 - 0s - loss: 0.4767 - acc: 0.7921 - val_loss: 0.5865 - val_acc: 0.7910\n",
      "Epoch 111/500\n",
      "534/534 - 0s - loss: 0.5582 - acc: 0.7566 - val_loss: 0.4849 - val_acc: 0.7687\n",
      "Epoch 112/500\n",
      "534/534 - 0s - loss: 0.4482 - acc: 0.8165 - val_loss: 0.4812 - val_acc: 0.7687\n",
      "Epoch 113/500\n",
      "534/534 - 0s - loss: 0.4549 - acc: 0.8015 - val_loss: 0.4974 - val_acc: 0.7985\n",
      "Epoch 114/500\n",
      "534/534 - 0s - loss: 0.4790 - acc: 0.7678 - val_loss: 0.4925 - val_acc: 0.7910\n",
      "Epoch 115/500\n",
      "534/534 - 0s - loss: 0.4981 - acc: 0.7659 - val_loss: 0.5794 - val_acc: 0.7985\n",
      "Epoch 116/500\n",
      "534/534 - 0s - loss: 0.6153 - acc: 0.7079 - val_loss: 0.6078 - val_acc: 0.7910\n",
      "Epoch 117/500\n",
      "534/534 - 0s - loss: 0.5994 - acc: 0.7303 - val_loss: 0.4811 - val_acc: 0.7985\n",
      "Epoch 118/500\n",
      "534/534 - 0s - loss: 0.4562 - acc: 0.8052 - val_loss: 0.4789 - val_acc: 0.7910\n",
      "Epoch 119/500\n",
      "534/534 - 0s - loss: 0.4516 - acc: 0.8090 - val_loss: 0.4748 - val_acc: 0.8060\n",
      "Epoch 120/500\n",
      "534/534 - 0s - loss: 0.4615 - acc: 0.7828 - val_loss: 0.5503 - val_acc: 0.7985\n",
      "Epoch 121/500\n",
      "534/534 - 0s - loss: 0.5188 - acc: 0.7828 - val_loss: 0.4833 - val_acc: 0.7537\n",
      "Epoch 122/500\n",
      "534/534 - 0s - loss: 0.4443 - acc: 0.8146 - val_loss: 0.6391 - val_acc: 0.6045\n",
      "Epoch 123/500\n",
      "534/534 - 0s - loss: 0.5773 - acc: 0.7266 - val_loss: 0.6561 - val_acc: 0.6716\n",
      "Epoch 124/500\n",
      "534/534 - 0s - loss: 0.5265 - acc: 0.7584 - val_loss: 0.5565 - val_acc: 0.6866\n",
      "Epoch 125/500\n",
      "534/534 - 0s - loss: 0.5173 - acc: 0.7603 - val_loss: 0.7084 - val_acc: 0.5821\n",
      "Epoch 126/500\n",
      "534/534 - 0s - loss: 0.5935 - acc: 0.7116 - val_loss: 0.5566 - val_acc: 0.6642\n",
      "Epoch 127/500\n",
      "534/534 - 0s - loss: 0.4639 - acc: 0.7865 - val_loss: 0.5039 - val_acc: 0.7164\n",
      "Epoch 128/500\n",
      "534/534 - 0s - loss: 0.4376 - acc: 0.8277 - val_loss: 0.4734 - val_acc: 0.7687\n",
      "Epoch 129/500\n",
      "534/534 - 0s - loss: 0.4698 - acc: 0.7828 - val_loss: 0.5657 - val_acc: 0.7910\n",
      "Epoch 130/500\n",
      "534/534 - 0s - loss: 0.5724 - acc: 0.7397 - val_loss: 0.6774 - val_acc: 0.7687\n",
      "Epoch 131/500\n",
      "534/534 - 0s - loss: 0.7173 - acc: 0.6891 - val_loss: 0.6001 - val_acc: 0.7910\n",
      "Epoch 132/500\n",
      "534/534 - 0s - loss: 0.5522 - acc: 0.7753 - val_loss: 0.4839 - val_acc: 0.7985\n",
      "Epoch 133/500\n",
      "534/534 - 0s - loss: 0.4400 - acc: 0.8277 - val_loss: 0.4733 - val_acc: 0.7761\n",
      "Epoch 134/500\n",
      "534/534 - 0s - loss: 0.4403 - acc: 0.8127 - val_loss: 0.4725 - val_acc: 0.7687\n",
      "Epoch 135/500\n",
      "534/534 - 0s - loss: 0.4457 - acc: 0.7959 - val_loss: 0.4953 - val_acc: 0.8060\n",
      "Epoch 136/500\n",
      "534/534 - 0s - loss: 0.4593 - acc: 0.8034 - val_loss: 0.4715 - val_acc: 0.7761\n",
      "Epoch 137/500\n",
      "534/534 - 0s - loss: 0.4309 - acc: 0.8277 - val_loss: 0.4830 - val_acc: 0.7910\n",
      "Epoch 138/500\n",
      "534/534 - 0s - loss: 0.4291 - acc: 0.8296 - val_loss: 0.4708 - val_acc: 0.7687\n",
      "Epoch 139/500\n",
      "534/534 - 0s - loss: 0.4313 - acc: 0.8202 - val_loss: 0.4703 - val_acc: 0.7612\n",
      "Epoch 140/500\n",
      "534/534 - 0s - loss: 0.4475 - acc: 0.8015 - val_loss: 0.5325 - val_acc: 0.7985\n",
      "Epoch 141/500\n",
      "534/534 - 0s - loss: 0.5922 - acc: 0.7266 - val_loss: 0.7089 - val_acc: 0.7612\n",
      "Epoch 142/500\n",
      "534/534 - 0s - loss: 0.6952 - acc: 0.7434 - val_loss: 0.4954 - val_acc: 0.8060\n",
      "Epoch 143/500\n",
      "534/534 - 0s - loss: 0.4562 - acc: 0.8202 - val_loss: 0.4852 - val_acc: 0.7910\n",
      "Epoch 144/500\n",
      "534/534 - 0s - loss: 0.4283 - acc: 0.8277 - val_loss: 0.4858 - val_acc: 0.7910\n",
      "Epoch 145/500\n",
      "534/534 - 0s - loss: 0.4264 - acc: 0.8296 - val_loss: 0.4791 - val_acc: 0.7836\n",
      "Epoch 146/500\n",
      "534/534 - 0s - loss: 0.4275 - acc: 0.8296 - val_loss: 0.4743 - val_acc: 0.7985\n",
      "Epoch 147/500\n",
      "534/534 - 0s - loss: 0.4340 - acc: 0.8127 - val_loss: 0.4964 - val_acc: 0.7612\n",
      "Epoch 148/500\n",
      "534/534 - 0s - loss: 0.4309 - acc: 0.8221 - val_loss: 0.5538 - val_acc: 0.7687\n",
      "Epoch 149/500\n",
      "534/534 - 0s - loss: 0.4881 - acc: 0.7996 - val_loss: 0.5871 - val_acc: 0.6418\n",
      "Epoch 150/500\n",
      "534/534 - 0s - loss: 0.4932 - acc: 0.7753 - val_loss: 0.5512 - val_acc: 0.6866\n",
      "Epoch 151/500\n",
      "534/534 - 0s - loss: 0.4955 - acc: 0.7790 - val_loss: 0.6298 - val_acc: 0.6418\n",
      "Epoch 152/500\n",
      "534/534 - 0s - loss: 0.5197 - acc: 0.7603 - val_loss: 0.5684 - val_acc: 0.6791\n",
      "Epoch 153/500\n",
      "534/534 - 0s - loss: 0.4856 - acc: 0.7790 - val_loss: 0.6875 - val_acc: 0.5821\n",
      "Epoch 154/500\n",
      "534/534 - 0s - loss: 0.6708 - acc: 0.7060 - val_loss: 0.6177 - val_acc: 0.6716\n",
      "Epoch 155/500\n",
      "534/534 - 0s - loss: 0.5337 - acc: 0.7640 - val_loss: 0.5470 - val_acc: 0.7015\n",
      "Epoch 156/500\n",
      "534/534 - 0s - loss: 0.4540 - acc: 0.8109 - val_loss: 0.5205 - val_acc: 0.7836\n",
      "Epoch 157/500\n",
      "534/534 - 0s - loss: 0.4524 - acc: 0.8090 - val_loss: 0.5115 - val_acc: 0.7761\n",
      "Epoch 158/500\n",
      "534/534 - 0s - loss: 0.4260 - acc: 0.8315 - val_loss: 0.4692 - val_acc: 0.7910\n",
      "Epoch 159/500\n",
      "534/534 - 0s - loss: 0.4216 - acc: 0.8315 - val_loss: 0.4698 - val_acc: 0.7761\n",
      "Epoch 160/500\n",
      "534/534 - 0s - loss: 0.4264 - acc: 0.8258 - val_loss: 0.4785 - val_acc: 0.7985\n",
      "Epoch 161/500\n",
      "534/534 - 0s - loss: 0.4861 - acc: 0.7790 - val_loss: 0.4808 - val_acc: 0.7985\n",
      "Epoch 162/500\n",
      "534/534 - 0s - loss: 0.4415 - acc: 0.8127 - val_loss: 0.4645 - val_acc: 0.7910\n",
      "Epoch 163/500\n",
      "534/534 - 0s - loss: 0.4274 - acc: 0.8127 - val_loss: 0.6551 - val_acc: 0.7015\n",
      "Epoch 164/500\n",
      "534/534 - 0s - loss: 0.5173 - acc: 0.7809 - val_loss: 0.5829 - val_acc: 0.7239\n",
      "Epoch 165/500\n",
      "534/534 - 0s - loss: 0.4714 - acc: 0.8034 - val_loss: 0.5575 - val_acc: 0.7090\n",
      "Epoch 166/500\n",
      "534/534 - 0s - loss: 0.4529 - acc: 0.8071 - val_loss: 0.5289 - val_acc: 0.7612\n",
      "Epoch 167/500\n",
      "534/534 - 0s - loss: 0.4719 - acc: 0.7996 - val_loss: 0.6116 - val_acc: 0.6567\n",
      "Epoch 168/500\n",
      "534/534 - 0s - loss: 0.4849 - acc: 0.7865 - val_loss: 0.5259 - val_acc: 0.6940\n",
      "Epoch 169/500\n",
      "534/534 - 0s - loss: 0.4621 - acc: 0.7996 - val_loss: 0.6675 - val_acc: 0.6119\n",
      "Epoch 170/500\n",
      "534/534 - 0s - loss: 0.6500 - acc: 0.7285 - val_loss: 0.6076 - val_acc: 0.6642\n",
      "Epoch 171/500\n",
      "534/534 - 0s - loss: 0.4701 - acc: 0.7865 - val_loss: 0.4906 - val_acc: 0.7687\n",
      "Epoch 172/500\n",
      "534/534 - 0s - loss: 0.4192 - acc: 0.8315 - val_loss: 0.4608 - val_acc: 0.7836\n",
      "Epoch 173/500\n",
      "534/534 - 0s - loss: 0.4253 - acc: 0.8146 - val_loss: 0.4558 - val_acc: 0.7910\n",
      "Epoch 174/500\n",
      "534/534 - 0s - loss: 0.4363 - acc: 0.8071 - val_loss: 0.4778 - val_acc: 0.8060\n",
      "Epoch 175/500\n",
      "534/534 - 0s - loss: 0.4504 - acc: 0.7996 - val_loss: 0.4574 - val_acc: 0.7910\n",
      "Epoch 176/500\n",
      "534/534 - 0s - loss: 0.4390 - acc: 0.7978 - val_loss: 0.4836 - val_acc: 0.7985\n",
      "Epoch 177/500\n",
      "534/534 - 0s - loss: 0.4621 - acc: 0.7903 - val_loss: 0.4640 - val_acc: 0.7985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 178/500\n",
      "534/534 - 0s - loss: 0.4867 - acc: 0.7846 - val_loss: 0.6617 - val_acc: 0.7985\n",
      "Epoch 179/500\n",
      "534/534 - 0s - loss: 0.6201 - acc: 0.7659 - val_loss: 0.4784 - val_acc: 0.7910\n",
      "Epoch 180/500\n",
      "534/534 - 0s - loss: 0.4376 - acc: 0.8146 - val_loss: 0.4726 - val_acc: 0.8060\n",
      "Epoch 181/500\n",
      "534/534 - 0s - loss: 0.4112 - acc: 0.8315 - val_loss: 0.4559 - val_acc: 0.7836\n",
      "Epoch 182/500\n",
      "534/534 - 0s - loss: 0.4091 - acc: 0.8202 - val_loss: 0.4644 - val_acc: 0.7985\n",
      "Epoch 183/500\n",
      "534/534 - 0s - loss: 0.4087 - acc: 0.8296 - val_loss: 0.4953 - val_acc: 0.7687\n",
      "Epoch 184/500\n",
      "534/534 - 0s - loss: 0.4292 - acc: 0.8127 - val_loss: 0.5863 - val_acc: 0.7537\n",
      "Epoch 185/500\n",
      "534/534 - 0s - loss: 0.5063 - acc: 0.7921 - val_loss: 0.5311 - val_acc: 0.7164\n",
      "Epoch 186/500\n",
      "534/534 - 0s - loss: 0.4375 - acc: 0.8015 - val_loss: 0.5270 - val_acc: 0.7836\n",
      "Epoch 187/500\n",
      "534/534 - 0s - loss: 0.4440 - acc: 0.8109 - val_loss: 0.6233 - val_acc: 0.7239\n",
      "Epoch 188/500\n",
      "534/534 - 0s - loss: 0.5546 - acc: 0.7566 - val_loss: 0.5652 - val_acc: 0.7164\n",
      "Epoch 189/500\n",
      "534/534 - 0s - loss: 0.4321 - acc: 0.8296 - val_loss: 0.4666 - val_acc: 0.7687\n",
      "Epoch 190/500\n",
      "534/534 - 0s - loss: 0.4186 - acc: 0.8277 - val_loss: 0.4613 - val_acc: 0.7985\n",
      "Epoch 191/500\n",
      "534/534 - 0s - loss: 0.4380 - acc: 0.8127 - val_loss: 0.4862 - val_acc: 0.8209\n",
      "Epoch 192/500\n",
      "534/534 - 0s - loss: 0.5023 - acc: 0.7790 - val_loss: 0.5437 - val_acc: 0.7985\n",
      "Epoch 193/500\n",
      "534/534 - 0s - loss: 0.5338 - acc: 0.7678 - val_loss: 0.4899 - val_acc: 0.8134\n",
      "Epoch 194/500\n",
      "534/534 - 0s - loss: 0.4805 - acc: 0.7940 - val_loss: 0.4688 - val_acc: 0.8060\n",
      "Epoch 195/500\n",
      "534/534 - 0s - loss: 0.4858 - acc: 0.7828 - val_loss: 0.6475 - val_acc: 0.7836\n",
      "Epoch 196/500\n",
      "534/534 - 0s - loss: 0.5889 - acc: 0.7697 - val_loss: 0.5216 - val_acc: 0.7836\n",
      "Epoch 197/500\n",
      "534/534 - 0s - loss: 0.4369 - acc: 0.8034 - val_loss: 0.5224 - val_acc: 0.7836\n",
      "Epoch 198/500\n",
      "534/534 - 0s - loss: 0.4594 - acc: 0.8165 - val_loss: 0.7410 - val_acc: 0.6119\n",
      "Epoch 199/500\n",
      "534/534 - 0s - loss: 0.7118 - acc: 0.7154 - val_loss: 0.7034 - val_acc: 0.6343\n",
      "Epoch 200/500\n",
      "534/534 - 0s - loss: 0.5456 - acc: 0.7659 - val_loss: 0.5368 - val_acc: 0.7836\n",
      "Epoch 201/500\n",
      "534/534 - 0s - loss: 0.4532 - acc: 0.8052 - val_loss: 0.6660 - val_acc: 0.6418\n",
      "Epoch 202/500\n",
      "534/534 - 0s - loss: 0.5099 - acc: 0.7809 - val_loss: 0.4964 - val_acc: 0.7687\n",
      "Epoch 203/500\n",
      "534/534 - 0s - loss: 0.4450 - acc: 0.8258 - val_loss: 0.4575 - val_acc: 0.7985\n",
      "Epoch 204/500\n",
      "534/534 - 0s - loss: 0.4053 - acc: 0.8277 - val_loss: 0.4614 - val_acc: 0.8060\n",
      "Epoch 205/500\n",
      "534/534 - 0s - loss: 0.4021 - acc: 0.8333 - val_loss: 0.5079 - val_acc: 0.7761\n",
      "Epoch 206/500\n",
      "534/534 - 0s - loss: 0.4152 - acc: 0.8202 - val_loss: 0.4797 - val_acc: 0.7836\n",
      "Epoch 207/500\n",
      "534/534 - 0s - loss: 0.4094 - acc: 0.8277 - val_loss: 0.5688 - val_acc: 0.7836\n",
      "Epoch 208/500\n",
      "534/534 - 0s - loss: 0.5055 - acc: 0.7884 - val_loss: 0.5106 - val_acc: 0.6940\n",
      "Epoch 209/500\n",
      "534/534 - 0s - loss: 0.4435 - acc: 0.8071 - val_loss: 0.6616 - val_acc: 0.7090\n",
      "Epoch 210/500\n",
      "534/534 - 0s - loss: 0.5111 - acc: 0.7903 - val_loss: 0.5453 - val_acc: 0.7687\n",
      "Epoch 211/500\n",
      "534/534 - 0s - loss: 0.4222 - acc: 0.8165 - val_loss: 0.4825 - val_acc: 0.7836\n",
      "Epoch 212/500\n",
      "534/534 - 0s - loss: 0.4018 - acc: 0.8352 - val_loss: 0.4638 - val_acc: 0.7910\n",
      "Epoch 213/500\n",
      "534/534 - 0s - loss: 0.4347 - acc: 0.8071 - val_loss: 0.4771 - val_acc: 0.7910\n",
      "Epoch 214/500\n",
      "534/534 - 0s - loss: 0.4297 - acc: 0.8071 - val_loss: 0.4844 - val_acc: 0.7985\n",
      "Epoch 215/500\n",
      "534/534 - 0s - loss: 0.3972 - acc: 0.8352 - val_loss: 0.4550 - val_acc: 0.7985\n",
      "Epoch 216/500\n",
      "534/534 - 0s - loss: 0.3981 - acc: 0.8390 - val_loss: 0.4541 - val_acc: 0.7836\n",
      "Epoch 217/500\n",
      "534/534 - 0s - loss: 0.4047 - acc: 0.8146 - val_loss: 0.4473 - val_acc: 0.7836\n",
      "Epoch 218/500\n",
      "534/534 - 0s - loss: 0.4170 - acc: 0.8184 - val_loss: 0.4648 - val_acc: 0.8060\n",
      "Epoch 219/500\n",
      "534/534 - 0s - loss: 0.4374 - acc: 0.7921 - val_loss: 0.4878 - val_acc: 0.7985\n",
      "Epoch 220/500\n",
      "534/534 - 0s - loss: 0.4752 - acc: 0.7865 - val_loss: 0.4743 - val_acc: 0.8060\n",
      "Epoch 221/500\n",
      "534/534 - 0s - loss: 0.4743 - acc: 0.7884 - val_loss: 0.5041 - val_acc: 0.8209\n",
      "Epoch 222/500\n",
      "534/534 - 0s - loss: 0.5099 - acc: 0.7790 - val_loss: 0.4836 - val_acc: 0.8209\n",
      "Epoch 223/500\n",
      "534/534 - 0s - loss: 0.4339 - acc: 0.8052 - val_loss: 0.4596 - val_acc: 0.7910\n",
      "Epoch 224/500\n",
      "534/534 - 0s - loss: 0.3960 - acc: 0.8296 - val_loss: 0.4496 - val_acc: 0.7836\n",
      "Epoch 225/500\n",
      "534/534 - 0s - loss: 0.4007 - acc: 0.8333 - val_loss: 0.4536 - val_acc: 0.7761\n",
      "Epoch 226/500\n",
      "534/534 - 0s - loss: 0.3965 - acc: 0.8258 - val_loss: 0.4575 - val_acc: 0.7910\n",
      "Epoch 227/500\n",
      "534/534 - 0s - loss: 0.3980 - acc: 0.8390 - val_loss: 0.4540 - val_acc: 0.7836\n",
      "Epoch 228/500\n",
      "534/534 - 0s - loss: 0.4091 - acc: 0.8109 - val_loss: 0.4551 - val_acc: 0.7985\n",
      "Epoch 229/500\n",
      "534/534 - 0s - loss: 0.3979 - acc: 0.8221 - val_loss: 0.4780 - val_acc: 0.7910\n",
      "Epoch 230/500\n",
      "534/534 - 0s - loss: 0.3975 - acc: 0.8315 - val_loss: 0.5550 - val_acc: 0.7761\n",
      "Epoch 231/500\n",
      "534/534 - 0s - loss: 0.4272 - acc: 0.8184 - val_loss: 0.5399 - val_acc: 0.7687\n",
      "Epoch 232/500\n",
      "534/534 - 0s - loss: 0.4446 - acc: 0.8034 - val_loss: 0.6258 - val_acc: 0.6866\n",
      "Epoch 233/500\n",
      "534/534 - 0s - loss: 0.4851 - acc: 0.7846 - val_loss: 0.5328 - val_acc: 0.7463\n",
      "Epoch 234/500\n",
      "534/534 - 0s - loss: 0.4188 - acc: 0.8221 - val_loss: 0.5159 - val_acc: 0.7836\n",
      "Epoch 235/500\n",
      "534/534 - 0s - loss: 0.3980 - acc: 0.8390 - val_loss: 0.4742 - val_acc: 0.7985\n",
      "Epoch 236/500\n",
      "534/534 - 0s - loss: 0.3887 - acc: 0.8408 - val_loss: 0.4580 - val_acc: 0.7910\n",
      "Epoch 237/500\n",
      "534/534 - 0s - loss: 0.3909 - acc: 0.8258 - val_loss: 0.5735 - val_acc: 0.7687\n",
      "Epoch 238/500\n",
      "534/534 - 0s - loss: 0.4490 - acc: 0.7996 - val_loss: 0.5498 - val_acc: 0.7761\n",
      "Epoch 239/500\n",
      "534/534 - 0s - loss: 0.4155 - acc: 0.8165 - val_loss: 0.4998 - val_acc: 0.7910\n",
      "Epoch 240/500\n",
      "534/534 - 0s - loss: 0.3896 - acc: 0.8333 - val_loss: 0.4657 - val_acc: 0.7910\n",
      "Epoch 241/500\n",
      "534/534 - 0s - loss: 0.3859 - acc: 0.8352 - val_loss: 0.5035 - val_acc: 0.7985\n",
      "Epoch 242/500\n",
      "534/534 - 0s - loss: 0.4017 - acc: 0.8296 - val_loss: 0.5520 - val_acc: 0.7761\n",
      "Epoch 243/500\n",
      "534/534 - 0s - loss: 0.4099 - acc: 0.8221 - val_loss: 0.5847 - val_acc: 0.7687\n",
      "Epoch 244/500\n",
      "534/534 - 0s - loss: 0.4315 - acc: 0.8127 - val_loss: 0.5364 - val_acc: 0.7910\n",
      "Epoch 245/500\n",
      "534/534 - 0s - loss: 0.4024 - acc: 0.8277 - val_loss: 0.4661 - val_acc: 0.7836\n",
      "Epoch 246/500\n",
      "534/534 - 0s - loss: 0.3970 - acc: 0.8277 - val_loss: 0.6837 - val_acc: 0.7090\n",
      "Epoch 247/500\n",
      "534/534 - 0s - loss: 0.4524 - acc: 0.8202 - val_loss: 0.4761 - val_acc: 0.7985\n",
      "Epoch 248/500\n",
      "534/534 - 0s - loss: 0.3892 - acc: 0.8371 - val_loss: 0.4935 - val_acc: 0.7910\n",
      "Epoch 249/500\n",
      "534/534 - 0s - loss: 0.3877 - acc: 0.8333 - val_loss: 0.5036 - val_acc: 0.7761\n",
      "Epoch 250/500\n",
      "534/534 - 0s - loss: 0.3941 - acc: 0.8333 - val_loss: 0.4917 - val_acc: 0.7910\n",
      "Epoch 251/500\n",
      "534/534 - 0s - loss: 0.3908 - acc: 0.8427 - val_loss: 0.5197 - val_acc: 0.7985\n",
      "Epoch 252/500\n",
      "534/534 - 0s - loss: 0.3866 - acc: 0.8390 - val_loss: 0.4725 - val_acc: 0.7910\n",
      "Epoch 253/500\n",
      "534/534 - 0s - loss: 0.3803 - acc: 0.8371 - val_loss: 0.4732 - val_acc: 0.7985\n",
      "Epoch 254/500\n",
      "534/534 - 0s - loss: 0.3827 - acc: 0.8390 - val_loss: 0.5196 - val_acc: 0.7836\n",
      "Epoch 255/500\n",
      "534/534 - 0s - loss: 0.4131 - acc: 0.8184 - val_loss: 0.5784 - val_acc: 0.7612\n",
      "Epoch 256/500\n",
      "534/534 - 0s - loss: 0.4146 - acc: 0.8202 - val_loss: 0.4907 - val_acc: 0.8060\n",
      "Epoch 257/500\n",
      "534/534 - 0s - loss: 0.3884 - acc: 0.8408 - val_loss: 0.4828 - val_acc: 0.7910\n",
      "Epoch 258/500\n",
      "534/534 - 0s - loss: 0.3822 - acc: 0.8315 - val_loss: 0.5116 - val_acc: 0.7836\n",
      "Epoch 259/500\n",
      "534/534 - 0s - loss: 0.4188 - acc: 0.8296 - val_loss: 0.5323 - val_acc: 0.7313\n",
      "Epoch 260/500\n",
      "534/534 - 0s - loss: 0.4049 - acc: 0.8427 - val_loss: 0.4997 - val_acc: 0.7985\n",
      "Epoch 261/500\n",
      "534/534 - 0s - loss: 0.4116 - acc: 0.8277 - val_loss: 0.6292 - val_acc: 0.6940\n",
      "Epoch 262/500\n",
      "534/534 - 0s - loss: 0.5111 - acc: 0.7884 - val_loss: 0.6042 - val_acc: 0.7164\n",
      "Epoch 263/500\n",
      "534/534 - 0s - loss: 0.4468 - acc: 0.8015 - val_loss: 0.5621 - val_acc: 0.7761\n",
      "Epoch 264/500\n",
      "534/534 - 0s - loss: 0.4151 - acc: 0.8221 - val_loss: 0.5489 - val_acc: 0.7836\n",
      "Epoch 265/500\n",
      "534/534 - 0s - loss: 0.3910 - acc: 0.8277 - val_loss: 0.4508 - val_acc: 0.7836\n",
      "Epoch 266/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "534/534 - 0s - loss: 0.3784 - acc: 0.8333 - val_loss: 0.4808 - val_acc: 0.7985\n",
      "Epoch 267/500\n",
      "534/534 - 0s - loss: 0.3768 - acc: 0.8390 - val_loss: 0.4597 - val_acc: 0.7910\n",
      "Epoch 268/500\n",
      "534/534 - 0s - loss: 0.3835 - acc: 0.8408 - val_loss: 0.4901 - val_acc: 0.7910\n",
      "Epoch 269/500\n",
      "534/534 - 0s - loss: 0.3975 - acc: 0.8390 - val_loss: 0.5634 - val_acc: 0.7836\n",
      "Epoch 270/500\n",
      "534/534 - 0s - loss: 0.4452 - acc: 0.8165 - val_loss: 0.6542 - val_acc: 0.7239\n",
      "Epoch 271/500\n",
      "534/534 - 0s - loss: 0.5173 - acc: 0.7940 - val_loss: 0.6547 - val_acc: 0.6716\n",
      "Epoch 272/500\n",
      "534/534 - 0s - loss: 0.4482 - acc: 0.8090 - val_loss: 0.4600 - val_acc: 0.7761\n",
      "Epoch 273/500\n",
      "534/534 - 0s - loss: 0.3814 - acc: 0.8315 - val_loss: 0.4480 - val_acc: 0.7537\n",
      "Epoch 274/500\n",
      "534/534 - 0s - loss: 0.3864 - acc: 0.8333 - val_loss: 0.4528 - val_acc: 0.7687\n",
      "Epoch 275/500\n",
      "534/534 - 0s - loss: 0.3883 - acc: 0.8240 - val_loss: 0.4507 - val_acc: 0.7612\n",
      "Epoch 276/500\n",
      "534/534 - 0s - loss: 0.3776 - acc: 0.8333 - val_loss: 0.4668 - val_acc: 0.7910\n",
      "Epoch 277/500\n",
      "534/534 - 0s - loss: 0.3724 - acc: 0.8408 - val_loss: 0.4885 - val_acc: 0.7985\n",
      "Epoch 278/500\n",
      "534/534 - 0s - loss: 0.3841 - acc: 0.8371 - val_loss: 0.5124 - val_acc: 0.8134\n",
      "Epoch 279/500\n",
      "534/534 - 0s - loss: 0.4076 - acc: 0.8240 - val_loss: 0.6049 - val_acc: 0.7388\n",
      "Epoch 280/500\n",
      "534/534 - 0s - loss: 0.4843 - acc: 0.8090 - val_loss: 0.5468 - val_acc: 0.7910\n",
      "Epoch 281/500\n",
      "534/534 - 0s - loss: 0.4440 - acc: 0.8184 - val_loss: 0.5864 - val_acc: 0.7015\n",
      "Epoch 282/500\n",
      "534/534 - 0s - loss: 0.4162 - acc: 0.8202 - val_loss: 0.5205 - val_acc: 0.7761\n",
      "Epoch 283/500\n",
      "534/534 - 0s - loss: 0.3907 - acc: 0.8352 - val_loss: 0.4780 - val_acc: 0.7910\n",
      "Epoch 284/500\n",
      "534/534 - 0s - loss: 0.3870 - acc: 0.8446 - val_loss: 0.5801 - val_acc: 0.7239\n",
      "Epoch 285/500\n",
      "534/534 - 0s - loss: 0.4192 - acc: 0.8221 - val_loss: 0.5217 - val_acc: 0.7985\n",
      "Epoch 286/500\n",
      "534/534 - 0s - loss: 0.3803 - acc: 0.8333 - val_loss: 0.5143 - val_acc: 0.7985\n",
      "Epoch 287/500\n",
      "534/534 - 0s - loss: 0.3757 - acc: 0.8446 - val_loss: 0.4758 - val_acc: 0.7836\n",
      "Epoch 288/500\n",
      "534/534 - 0s - loss: 0.3921 - acc: 0.8202 - val_loss: 0.7400 - val_acc: 0.7090\n",
      "Epoch 289/500\n",
      "534/534 - 0s - loss: 0.5144 - acc: 0.7921 - val_loss: 0.6377 - val_acc: 0.6791\n",
      "Epoch 290/500\n",
      "534/534 - 0s - loss: 0.4456 - acc: 0.7996 - val_loss: 0.4937 - val_acc: 0.7836\n",
      "Epoch 291/500\n",
      "534/534 - 0s - loss: 0.3891 - acc: 0.8390 - val_loss: 0.5133 - val_acc: 0.7910\n",
      "Epoch 292/500\n",
      "534/534 - 0s - loss: 0.3784 - acc: 0.8408 - val_loss: 0.4862 - val_acc: 0.7836\n",
      "Epoch 293/500\n",
      "534/534 - 0s - loss: 0.3742 - acc: 0.8333 - val_loss: 0.5067 - val_acc: 0.7761\n",
      "Epoch 294/500\n",
      "534/534 - 0s - loss: 0.3828 - acc: 0.8221 - val_loss: 0.5201 - val_acc: 0.7910\n",
      "Epoch 295/500\n",
      "534/534 - 0s - loss: 0.3784 - acc: 0.8427 - val_loss: 0.4962 - val_acc: 0.7985\n",
      "Epoch 296/500\n",
      "534/534 - 0s - loss: 0.3715 - acc: 0.8408 - val_loss: 0.4849 - val_acc: 0.7910\n",
      "Epoch 297/500\n",
      "534/534 - 0s - loss: 0.3771 - acc: 0.8483 - val_loss: 0.5486 - val_acc: 0.7761\n",
      "Epoch 298/500\n",
      "534/534 - 0s - loss: 0.4134 - acc: 0.8165 - val_loss: 0.6786 - val_acc: 0.7463\n",
      "Epoch 299/500\n",
      "534/534 - 0s - loss: 0.5338 - acc: 0.8034 - val_loss: 0.5824 - val_acc: 0.7090\n",
      "Epoch 300/500\n",
      "534/534 - 0s - loss: 0.3866 - acc: 0.8539 - val_loss: 0.4649 - val_acc: 0.7836\n",
      "Epoch 301/500\n",
      "534/534 - 0s - loss: 0.3697 - acc: 0.8408 - val_loss: 0.4698 - val_acc: 0.7761\n",
      "Epoch 302/500\n",
      "534/534 - 0s - loss: 0.3735 - acc: 0.8390 - val_loss: 0.4623 - val_acc: 0.7612\n",
      "Epoch 303/500\n",
      "534/534 - 0s - loss: 0.3699 - acc: 0.8427 - val_loss: 0.6237 - val_acc: 0.7090\n",
      "Epoch 304/500\n",
      "534/534 - 0s - loss: 0.4608 - acc: 0.7903 - val_loss: 0.5894 - val_acc: 0.7388\n",
      "Epoch 305/500\n",
      "534/534 - 0s - loss: 0.3913 - acc: 0.8483 - val_loss: 0.4929 - val_acc: 0.8060\n",
      "Epoch 306/500\n",
      "534/534 - 0s - loss: 0.3743 - acc: 0.8315 - val_loss: 0.5509 - val_acc: 0.7761\n",
      "Epoch 307/500\n",
      "534/534 - 0s - loss: 0.3875 - acc: 0.8446 - val_loss: 0.4983 - val_acc: 0.7910\n",
      "Epoch 308/500\n",
      "534/534 - 0s - loss: 0.3649 - acc: 0.8539 - val_loss: 0.4738 - val_acc: 0.7836\n",
      "Epoch 309/500\n",
      "534/534 - 0s - loss: 0.3627 - acc: 0.8446 - val_loss: 0.5189 - val_acc: 0.7985\n",
      "Epoch 310/500\n",
      "534/534 - 0s - loss: 0.4034 - acc: 0.8127 - val_loss: 0.7135 - val_acc: 0.6567\n",
      "Epoch 311/500\n",
      "534/534 - 0s - loss: 0.5028 - acc: 0.7978 - val_loss: 0.5162 - val_acc: 0.7463\n",
      "Epoch 312/500\n",
      "534/534 - 0s - loss: 0.3852 - acc: 0.8371 - val_loss: 0.5212 - val_acc: 0.7761\n",
      "Epoch 313/500\n",
      "534/534 - 0s - loss: 0.3733 - acc: 0.8483 - val_loss: 0.5122 - val_acc: 0.7910\n",
      "Epoch 314/500\n",
      "534/534 - 0s - loss: 0.3668 - acc: 0.8483 - val_loss: 0.4665 - val_acc: 0.7612\n",
      "Epoch 315/500\n",
      "534/534 - 0s - loss: 0.3668 - acc: 0.8502 - val_loss: 0.4610 - val_acc: 0.7761\n",
      "Epoch 316/500\n",
      "534/534 - 0s - loss: 0.3607 - acc: 0.8558 - val_loss: 0.4787 - val_acc: 0.7836\n",
      "Epoch 317/500\n",
      "534/534 - 0s - loss: 0.3667 - acc: 0.8427 - val_loss: 0.5860 - val_acc: 0.7612\n",
      "Epoch 318/500\n",
      "534/534 - 0s - loss: 0.4189 - acc: 0.8258 - val_loss: 0.5018 - val_acc: 0.7910\n",
      "Epoch 319/500\n",
      "534/534 - 0s - loss: 0.3837 - acc: 0.8371 - val_loss: 0.5899 - val_acc: 0.7687\n",
      "Epoch 320/500\n",
      "534/534 - 0s - loss: 0.3900 - acc: 0.8202 - val_loss: 0.5102 - val_acc: 0.7985\n",
      "Epoch 321/500\n",
      "534/534 - 0s - loss: 0.3951 - acc: 0.8371 - val_loss: 0.6835 - val_acc: 0.6791\n",
      "Epoch 322/500\n",
      "534/534 - 0s - loss: 0.5026 - acc: 0.7903 - val_loss: 0.5727 - val_acc: 0.7015\n",
      "Epoch 323/500\n",
      "534/534 - 0s - loss: 0.4067 - acc: 0.8390 - val_loss: 0.5184 - val_acc: 0.8060\n",
      "Epoch 324/500\n",
      "534/534 - 0s - loss: 0.3726 - acc: 0.8390 - val_loss: 0.5196 - val_acc: 0.8060\n",
      "Epoch 325/500\n",
      "534/534 - 0s - loss: 0.3725 - acc: 0.8464 - val_loss: 0.5185 - val_acc: 0.8060\n",
      "Epoch 326/500\n",
      "534/534 - 0s - loss: 0.3778 - acc: 0.8427 - val_loss: 0.5495 - val_acc: 0.7761\n",
      "Epoch 327/500\n",
      "534/534 - 0s - loss: 0.3740 - acc: 0.8464 - val_loss: 0.4838 - val_acc: 0.8060\n",
      "Epoch 328/500\n",
      "534/534 - 0s - loss: 0.3565 - acc: 0.8483 - val_loss: 0.4671 - val_acc: 0.7836\n",
      "Epoch 329/500\n",
      "534/534 - 0s - loss: 0.3548 - acc: 0.8502 - val_loss: 0.4843 - val_acc: 0.8060\n",
      "Epoch 330/500\n",
      "534/534 - 0s - loss: 0.3545 - acc: 0.8539 - val_loss: 0.4629 - val_acc: 0.7612\n",
      "Epoch 331/500\n",
      "534/534 - 0s - loss: 0.3701 - acc: 0.8539 - val_loss: 0.4638 - val_acc: 0.7761\n",
      "Epoch 332/500\n",
      "534/534 - 0s - loss: 0.4082 - acc: 0.8146 - val_loss: 0.4892 - val_acc: 0.7910\n",
      "Epoch 333/500\n",
      "534/534 - 0s - loss: 0.4290 - acc: 0.8240 - val_loss: 0.4864 - val_acc: 0.7985\n",
      "Epoch 334/500\n",
      "534/534 - 0s - loss: 0.4732 - acc: 0.7959 - val_loss: 0.5031 - val_acc: 0.7910\n",
      "Epoch 335/500\n",
      "534/534 - 0s - loss: 0.4105 - acc: 0.8146 - val_loss: 0.4570 - val_acc: 0.7612\n",
      "Epoch 336/500\n",
      "534/534 - 0s - loss: 0.3657 - acc: 0.8352 - val_loss: 0.5871 - val_acc: 0.7836\n",
      "Epoch 337/500\n",
      "534/534 - 0s - loss: 0.3854 - acc: 0.8446 - val_loss: 0.5202 - val_acc: 0.7910\n",
      "Epoch 338/500\n",
      "534/534 - 0s - loss: 0.3626 - acc: 0.8577 - val_loss: 0.4928 - val_acc: 0.8060\n",
      "Epoch 339/500\n",
      "534/534 - 0s - loss: 0.3646 - acc: 0.8446 - val_loss: 0.5402 - val_acc: 0.7985\n",
      "Epoch 340/500\n",
      "534/534 - 0s - loss: 0.3593 - acc: 0.8596 - val_loss: 0.4649 - val_acc: 0.7537\n",
      "Epoch 341/500\n",
      "534/534 - 0s - loss: 0.3592 - acc: 0.8521 - val_loss: 0.4610 - val_acc: 0.7761\n",
      "Epoch 342/500\n",
      "534/534 - 0s - loss: 0.3516 - acc: 0.8483 - val_loss: 0.5040 - val_acc: 0.7910\n",
      "Epoch 343/500\n",
      "534/534 - 0s - loss: 0.3776 - acc: 0.8240 - val_loss: 0.7257 - val_acc: 0.6642\n",
      "Epoch 344/500\n",
      "534/534 - 0s - loss: 0.6156 - acc: 0.7753 - val_loss: 0.7014 - val_acc: 0.6940\n",
      "Epoch 345/500\n",
      "534/534 - 0s - loss: 0.4286 - acc: 0.8240 - val_loss: 0.4935 - val_acc: 0.7985\n",
      "Epoch 346/500\n",
      "534/534 - 0s - loss: 0.3551 - acc: 0.8521 - val_loss: 0.4743 - val_acc: 0.7836\n",
      "Epoch 347/500\n",
      "534/534 - 0s - loss: 0.3548 - acc: 0.8502 - val_loss: 0.4587 - val_acc: 0.7687\n",
      "Epoch 348/500\n",
      "534/534 - 0s - loss: 0.3694 - acc: 0.8427 - val_loss: 0.4615 - val_acc: 0.7463\n",
      "Epoch 349/500\n",
      "534/534 - 0s - loss: 0.3936 - acc: 0.8277 - val_loss: 0.4625 - val_acc: 0.7537\n",
      "Epoch 350/500\n",
      "534/534 - 0s - loss: 0.3712 - acc: 0.8296 - val_loss: 0.4679 - val_acc: 0.7836\n",
      "Epoch 351/500\n",
      "534/534 - 0s - loss: 0.3542 - acc: 0.8502 - val_loss: 0.4605 - val_acc: 0.7687\n",
      "Epoch 352/500\n",
      "534/534 - 0s - loss: 0.3519 - acc: 0.8558 - val_loss: 0.4901 - val_acc: 0.7836\n",
      "Epoch 353/500\n",
      "534/534 - 0s - loss: 0.3548 - acc: 0.8521 - val_loss: 0.5227 - val_acc: 0.7910\n",
      "Epoch 354/500\n",
      "534/534 - 0s - loss: 0.3548 - acc: 0.8577 - val_loss: 0.4667 - val_acc: 0.7612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 355/500\n",
      "534/534 - 0s - loss: 0.3651 - acc: 0.8427 - val_loss: 0.4585 - val_acc: 0.7687\n",
      "Epoch 356/500\n",
      "534/534 - 0s - loss: 0.3738 - acc: 0.8352 - val_loss: 0.4563 - val_acc: 0.7612\n",
      "Epoch 357/500\n",
      "534/534 - 0s - loss: 0.3801 - acc: 0.8408 - val_loss: 0.4713 - val_acc: 0.7836\n",
      "Epoch 358/500\n",
      "534/534 - 0s - loss: 0.3998 - acc: 0.8240 - val_loss: 0.4581 - val_acc: 0.7612\n",
      "Epoch 359/500\n",
      "534/534 - 0s - loss: 0.4150 - acc: 0.8146 - val_loss: 0.5343 - val_acc: 0.8134\n",
      "Epoch 360/500\n",
      "534/534 - 0s - loss: 0.4978 - acc: 0.7828 - val_loss: 0.4771 - val_acc: 0.7761\n",
      "Epoch 361/500\n",
      "534/534 - 0s - loss: 0.4521 - acc: 0.7903 - val_loss: 0.5095 - val_acc: 0.7910\n",
      "Epoch 362/500\n",
      "534/534 - 0s - loss: 0.3983 - acc: 0.8221 - val_loss: 0.4990 - val_acc: 0.7985\n",
      "Epoch 363/500\n",
      "534/534 - 0s - loss: 0.3704 - acc: 0.8390 - val_loss: 0.6766 - val_acc: 0.6791\n",
      "Epoch 364/500\n",
      "534/534 - 0s - loss: 0.4184 - acc: 0.8315 - val_loss: 0.5047 - val_acc: 0.7985\n",
      "Epoch 365/500\n",
      "534/534 - 0s - loss: 0.3574 - acc: 0.8521 - val_loss: 0.5035 - val_acc: 0.7836\n",
      "Epoch 366/500\n",
      "534/534 - 0s - loss: 0.3491 - acc: 0.8614 - val_loss: 0.4909 - val_acc: 0.7761\n",
      "Epoch 367/500\n",
      "534/534 - 0s - loss: 0.3447 - acc: 0.8558 - val_loss: 0.4877 - val_acc: 0.7687\n",
      "Epoch 368/500\n",
      "534/534 - 0s - loss: 0.3460 - acc: 0.8521 - val_loss: 0.5293 - val_acc: 0.7910\n",
      "Epoch 369/500\n",
      "534/534 - 0s - loss: 0.3558 - acc: 0.8483 - val_loss: 0.5073 - val_acc: 0.7836\n",
      "Epoch 370/500\n",
      "534/534 - 0s - loss: 0.3470 - acc: 0.8614 - val_loss: 0.5005 - val_acc: 0.7910\n",
      "Epoch 371/500\n",
      "534/534 - 0s - loss: 0.3435 - acc: 0.8596 - val_loss: 0.4680 - val_acc: 0.7612\n",
      "Epoch 372/500\n",
      "534/534 - 0s - loss: 0.3797 - acc: 0.8539 - val_loss: 0.4775 - val_acc: 0.7985\n",
      "Epoch 373/500\n",
      "534/534 - 0s - loss: 0.3642 - acc: 0.8371 - val_loss: 0.4753 - val_acc: 0.7612\n",
      "Epoch 374/500\n",
      "534/534 - 0s - loss: 0.3442 - acc: 0.8614 - val_loss: 0.5009 - val_acc: 0.7910\n",
      "Epoch 375/500\n",
      "534/534 - 0s - loss: 0.3478 - acc: 0.8596 - val_loss: 0.5017 - val_acc: 0.7985\n",
      "Epoch 376/500\n",
      "534/534 - 0s - loss: 0.3434 - acc: 0.8596 - val_loss: 0.4797 - val_acc: 0.7687\n",
      "Epoch 377/500\n",
      "534/534 - 0s - loss: 0.3443 - acc: 0.8558 - val_loss: 0.5482 - val_acc: 0.7761\n",
      "Epoch 378/500\n",
      "534/534 - 0s - loss: 0.3947 - acc: 0.8258 - val_loss: 0.7191 - val_acc: 0.6940\n",
      "Epoch 379/500\n",
      "534/534 - 0s - loss: 0.4265 - acc: 0.8296 - val_loss: 0.5463 - val_acc: 0.7836\n",
      "Epoch 380/500\n",
      "534/534 - 0s - loss: 0.3587 - acc: 0.8446 - val_loss: 0.5100 - val_acc: 0.7761\n",
      "Epoch 381/500\n",
      "534/534 - 0s - loss: 0.3458 - acc: 0.8596 - val_loss: 0.4842 - val_acc: 0.7612\n",
      "Epoch 382/500\n",
      "534/534 - 0s - loss: 0.3471 - acc: 0.8539 - val_loss: 0.4792 - val_acc: 0.7687\n",
      "Epoch 383/500\n",
      "534/534 - 0s - loss: 0.3522 - acc: 0.8446 - val_loss: 0.4769 - val_acc: 0.7612\n",
      "Epoch 384/500\n",
      "534/534 - 0s - loss: 0.3512 - acc: 0.8483 - val_loss: 0.4775 - val_acc: 0.7612\n",
      "Epoch 385/500\n",
      "534/534 - 0s - loss: 0.3485 - acc: 0.8558 - val_loss: 0.4733 - val_acc: 0.7687\n",
      "Epoch 386/500\n",
      "534/534 - 0s - loss: 0.3515 - acc: 0.8521 - val_loss: 0.4987 - val_acc: 0.7836\n",
      "Epoch 387/500\n",
      "534/534 - 0s - loss: 0.3421 - acc: 0.8521 - val_loss: 0.4913 - val_acc: 0.7612\n",
      "Epoch 388/500\n",
      "534/534 - 0s - loss: 0.3401 - acc: 0.8614 - val_loss: 0.4811 - val_acc: 0.7612\n",
      "Epoch 389/500\n",
      "534/534 - 0s - loss: 0.3508 - acc: 0.8577 - val_loss: 0.4808 - val_acc: 0.7612\n",
      "Epoch 390/500\n",
      "534/534 - 0s - loss: 0.3789 - acc: 0.8408 - val_loss: 0.4969 - val_acc: 0.8209\n",
      "Epoch 391/500\n",
      "534/534 - 0s - loss: 0.4102 - acc: 0.8277 - val_loss: 0.4856 - val_acc: 0.7836\n",
      "Epoch 392/500\n",
      "534/534 - 0s - loss: 0.3686 - acc: 0.8446 - val_loss: 0.4686 - val_acc: 0.7612\n",
      "Epoch 393/500\n",
      "534/534 - 0s - loss: 0.3526 - acc: 0.8483 - val_loss: 0.4838 - val_acc: 0.7687\n",
      "Epoch 394/500\n",
      "534/534 - 0s - loss: 0.3391 - acc: 0.8577 - val_loss: 0.4976 - val_acc: 0.7836\n",
      "Epoch 395/500\n",
      "534/534 - 0s - loss: 0.3403 - acc: 0.8577 - val_loss: 0.5162 - val_acc: 0.7910\n",
      "Epoch 396/500\n",
      "534/534 - 0s - loss: 0.3647 - acc: 0.8464 - val_loss: 0.7254 - val_acc: 0.6866\n",
      "Epoch 397/500\n",
      "534/534 - 0s - loss: 0.5345 - acc: 0.7809 - val_loss: 0.6777 - val_acc: 0.6866\n",
      "Epoch 398/500\n",
      "534/534 - 0s - loss: 0.4302 - acc: 0.8202 - val_loss: 0.5479 - val_acc: 0.7836\n",
      "Epoch 399/500\n",
      "534/534 - 0s - loss: 0.3547 - acc: 0.8577 - val_loss: 0.4905 - val_acc: 0.7836\n",
      "Epoch 400/500\n",
      "534/534 - 0s - loss: 0.3390 - acc: 0.8577 - val_loss: 0.4863 - val_acc: 0.7761\n",
      "Epoch 401/500\n",
      "534/534 - 0s - loss: 0.3388 - acc: 0.8558 - val_loss: 0.5455 - val_acc: 0.7910\n",
      "Epoch 402/500\n",
      "534/534 - 0s - loss: 0.3542 - acc: 0.8558 - val_loss: 0.5310 - val_acc: 0.7985\n",
      "Epoch 403/500\n",
      "534/534 - 0s - loss: 0.3508 - acc: 0.8614 - val_loss: 0.5527 - val_acc: 0.7910\n",
      "Epoch 404/500\n",
      "534/534 - 0s - loss: 0.3592 - acc: 0.8427 - val_loss: 0.5922 - val_acc: 0.7687\n",
      "Epoch 405/500\n",
      "534/534 - 0s - loss: 0.3614 - acc: 0.8446 - val_loss: 0.5216 - val_acc: 0.7836\n",
      "Epoch 406/500\n",
      "534/534 - 0s - loss: 0.3413 - acc: 0.8633 - val_loss: 0.4807 - val_acc: 0.7463\n",
      "Epoch 407/500\n",
      "534/534 - 0s - loss: 0.3578 - acc: 0.8521 - val_loss: 0.4731 - val_acc: 0.7612\n",
      "Epoch 408/500\n",
      "534/534 - 0s - loss: 0.3598 - acc: 0.8446 - val_loss: 0.4750 - val_acc: 0.7537\n",
      "Epoch 409/500\n",
      "534/534 - 0s - loss: 0.3389 - acc: 0.8558 - val_loss: 0.4780 - val_acc: 0.7537\n",
      "Epoch 410/500\n",
      "534/534 - 0s - loss: 0.3364 - acc: 0.8652 - val_loss: 0.4775 - val_acc: 0.7537\n",
      "Epoch 411/500\n",
      "534/534 - 0s - loss: 0.3329 - acc: 0.8614 - val_loss: 0.5406 - val_acc: 0.7985\n",
      "Epoch 412/500\n",
      "534/534 - 0s - loss: 0.3405 - acc: 0.8577 - val_loss: 0.4961 - val_acc: 0.7910\n",
      "Epoch 413/500\n",
      "534/534 - 0s - loss: 0.3341 - acc: 0.8596 - val_loss: 0.5149 - val_acc: 0.7836\n",
      "Epoch 414/500\n",
      "534/534 - 0s - loss: 0.3366 - acc: 0.8577 - val_loss: 0.5075 - val_acc: 0.7910\n",
      "Epoch 415/500\n",
      "534/534 - 0s - loss: 0.3351 - acc: 0.8614 - val_loss: 0.5277 - val_acc: 0.7985\n",
      "Epoch 416/500\n",
      "534/534 - 0s - loss: 0.3326 - acc: 0.8689 - val_loss: 0.4868 - val_acc: 0.7612\n",
      "Epoch 417/500\n",
      "534/534 - 0s - loss: 0.3486 - acc: 0.8577 - val_loss: 0.4733 - val_acc: 0.7612\n",
      "Epoch 418/500\n",
      "534/534 - 0s - loss: 0.3368 - acc: 0.8652 - val_loss: 0.4774 - val_acc: 0.7537\n",
      "Epoch 419/500\n",
      "534/534 - 0s - loss: 0.3299 - acc: 0.8670 - val_loss: 0.5111 - val_acc: 0.7910\n",
      "Epoch 420/500\n",
      "534/534 - 0s - loss: 0.3326 - acc: 0.8614 - val_loss: 0.4943 - val_acc: 0.7910\n",
      "Epoch 421/500\n",
      "534/534 - 0s - loss: 0.3305 - acc: 0.8577 - val_loss: 0.5135 - val_acc: 0.7836\n",
      "Epoch 422/500\n",
      "534/534 - 0s - loss: 0.3439 - acc: 0.8483 - val_loss: 0.6116 - val_acc: 0.7164\n",
      "Epoch 423/500\n",
      "534/534 - 0s - loss: 0.3659 - acc: 0.8427 - val_loss: 0.5111 - val_acc: 0.7836\n",
      "Epoch 424/500\n",
      "534/534 - 0s - loss: 0.3305 - acc: 0.8614 - val_loss: 0.5087 - val_acc: 0.7836\n",
      "Epoch 425/500\n",
      "534/534 - 0s - loss: 0.3285 - acc: 0.8614 - val_loss: 0.4828 - val_acc: 0.7537\n",
      "Epoch 426/500\n",
      "534/534 - 0s - loss: 0.3372 - acc: 0.8596 - val_loss: 0.4863 - val_acc: 0.7537\n",
      "Epoch 427/500\n",
      "534/534 - 0s - loss: 0.3444 - acc: 0.8502 - val_loss: 0.4840 - val_acc: 0.7612\n",
      "Epoch 428/500\n",
      "534/534 - 0s - loss: 0.3572 - acc: 0.8521 - val_loss: 0.5028 - val_acc: 0.7910\n",
      "Epoch 429/500\n",
      "534/534 - 0s - loss: 0.4306 - acc: 0.8202 - val_loss: 0.5836 - val_acc: 0.8134\n",
      "Epoch 430/500\n",
      "534/534 - 0s - loss: 0.4791 - acc: 0.8333 - val_loss: 0.5124 - val_acc: 0.7687\n",
      "Epoch 431/500\n",
      "534/534 - 0s - loss: 0.3538 - acc: 0.8483 - val_loss: 0.5181 - val_acc: 0.7836\n",
      "Epoch 432/500\n",
      "534/534 - 0s - loss: 0.3312 - acc: 0.8521 - val_loss: 0.5522 - val_acc: 0.7836\n",
      "Epoch 433/500\n",
      "534/534 - 0s - loss: 0.3367 - acc: 0.8652 - val_loss: 0.5423 - val_acc: 0.7910\n",
      "Epoch 434/500\n",
      "534/534 - 0s - loss: 0.3316 - acc: 0.8614 - val_loss: 0.5081 - val_acc: 0.7836\n",
      "Epoch 435/500\n",
      "534/534 - 0s - loss: 0.3268 - acc: 0.8614 - val_loss: 0.4975 - val_acc: 0.7612\n",
      "Epoch 436/500\n",
      "534/534 - 0s - loss: 0.3254 - acc: 0.8614 - val_loss: 0.5344 - val_acc: 0.7910\n",
      "Epoch 437/500\n",
      "534/534 - 0s - loss: 0.3294 - acc: 0.8596 - val_loss: 0.5215 - val_acc: 0.7836\n",
      "Epoch 438/500\n",
      "534/534 - 0s - loss: 0.3302 - acc: 0.8539 - val_loss: 0.5558 - val_acc: 0.7910\n",
      "Epoch 439/500\n",
      "534/534 - 0s - loss: 0.3440 - acc: 0.8539 - val_loss: 0.5737 - val_acc: 0.7836\n",
      "Epoch 440/500\n",
      "534/534 - 0s - loss: 0.3366 - acc: 0.8689 - val_loss: 0.5322 - val_acc: 0.7910\n",
      "Epoch 441/500\n",
      "534/534 - 0s - loss: 0.3303 - acc: 0.8596 - val_loss: 0.5750 - val_acc: 0.7836\n",
      "Epoch 442/500\n",
      "534/534 - 0s - loss: 0.3460 - acc: 0.8521 - val_loss: 0.6008 - val_acc: 0.7836\n",
      "Epoch 443/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "534/534 - 0s - loss: 0.3681 - acc: 0.8483 - val_loss: 0.7033 - val_acc: 0.7015\n",
      "Epoch 444/500\n",
      "534/534 - 0s - loss: 0.4504 - acc: 0.8127 - val_loss: 0.6649 - val_acc: 0.7090\n",
      "Epoch 445/500\n",
      "534/534 - 0s - loss: 0.3837 - acc: 0.8296 - val_loss: 0.5895 - val_acc: 0.7910\n",
      "Epoch 446/500\n",
      "534/534 - 0s - loss: 0.3410 - acc: 0.8633 - val_loss: 0.5419 - val_acc: 0.7985\n",
      "Epoch 447/500\n",
      "534/534 - 0s - loss: 0.3460 - acc: 0.8577 - val_loss: 0.6284 - val_acc: 0.7313\n",
      "Epoch 448/500\n",
      "534/534 - 0s - loss: 0.3754 - acc: 0.8371 - val_loss: 0.6229 - val_acc: 0.7239\n",
      "Epoch 449/500\n",
      "534/534 - 0s - loss: 0.3428 - acc: 0.8539 - val_loss: 0.5070 - val_acc: 0.7612\n",
      "Epoch 450/500\n",
      "534/534 - 0s - loss: 0.3426 - acc: 0.8558 - val_loss: 0.6618 - val_acc: 0.7612\n",
      "Epoch 451/500\n",
      "534/534 - 0s - loss: 0.3897 - acc: 0.8371 - val_loss: 0.6658 - val_acc: 0.7612\n",
      "Epoch 452/500\n",
      "534/534 - 0s - loss: 0.3735 - acc: 0.8333 - val_loss: 0.6373 - val_acc: 0.7761\n",
      "Epoch 453/500\n",
      "534/534 - 0s - loss: 0.3473 - acc: 0.8614 - val_loss: 0.5274 - val_acc: 0.7836\n",
      "Epoch 454/500\n",
      "534/534 - 0s - loss: 0.3223 - acc: 0.8633 - val_loss: 0.5024 - val_acc: 0.7612\n",
      "Epoch 455/500\n",
      "534/534 - 0s - loss: 0.3284 - acc: 0.8614 - val_loss: 0.4930 - val_acc: 0.7537\n",
      "Epoch 456/500\n",
      "534/534 - 0s - loss: 0.3359 - acc: 0.8558 - val_loss: 0.5169 - val_acc: 0.7612\n",
      "Epoch 457/500\n",
      "534/534 - 0s - loss: 0.3241 - acc: 0.8596 - val_loss: 0.5196 - val_acc: 0.7612\n",
      "Epoch 458/500\n",
      "534/534 - 0s - loss: 0.3235 - acc: 0.8670 - val_loss: 0.5038 - val_acc: 0.7463\n",
      "Epoch 459/500\n",
      "534/534 - 0s - loss: 0.3393 - acc: 0.8596 - val_loss: 0.5059 - val_acc: 0.7687\n",
      "Epoch 460/500\n",
      "534/534 - 0s - loss: 0.3471 - acc: 0.8464 - val_loss: 0.5108 - val_acc: 0.7537\n",
      "Epoch 461/500\n",
      "534/534 - 0s - loss: 0.3352 - acc: 0.8521 - val_loss: 0.4980 - val_acc: 0.7612\n",
      "Epoch 462/500\n",
      "534/534 - 0s - loss: 0.3406 - acc: 0.8483 - val_loss: 0.5044 - val_acc: 0.7463\n",
      "Epoch 463/500\n",
      "534/534 - 0s - loss: 0.3222 - acc: 0.8577 - val_loss: 0.5164 - val_acc: 0.7687\n",
      "Epoch 464/500\n",
      "534/534 - 0s - loss: 0.3206 - acc: 0.8708 - val_loss: 0.5070 - val_acc: 0.7463\n",
      "Epoch 465/500\n",
      "534/534 - 0s - loss: 0.3226 - acc: 0.8633 - val_loss: 0.5223 - val_acc: 0.7687\n",
      "Epoch 466/500\n",
      "534/534 - 0s - loss: 0.3191 - acc: 0.8708 - val_loss: 0.5277 - val_acc: 0.7910\n",
      "Epoch 467/500\n",
      "534/534 - 0s - loss: 0.3188 - acc: 0.8652 - val_loss: 0.5542 - val_acc: 0.7910\n",
      "Epoch 468/500\n",
      "534/534 - 0s - loss: 0.3239 - acc: 0.8633 - val_loss: 0.5563 - val_acc: 0.7836\n",
      "Epoch 469/500\n",
      "534/534 - 0s - loss: 0.3258 - acc: 0.8745 - val_loss: 0.5757 - val_acc: 0.7910\n",
      "Epoch 470/500\n",
      "534/534 - 0s - loss: 0.3393 - acc: 0.8558 - val_loss: 0.6463 - val_acc: 0.7687\n",
      "Epoch 471/500\n",
      "534/534 - 0s - loss: 0.3700 - acc: 0.8483 - val_loss: 0.7248 - val_acc: 0.7164\n",
      "Epoch 472/500\n",
      "534/534 - 0s - loss: 0.4512 - acc: 0.7996 - val_loss: 0.7879 - val_acc: 0.6866\n",
      "Epoch 473/500\n",
      "534/534 - 0s - loss: 0.4369 - acc: 0.8146 - val_loss: 0.6283 - val_acc: 0.7239\n",
      "Epoch 474/500\n",
      "534/534 - 0s - loss: 0.3582 - acc: 0.8596 - val_loss: 0.6013 - val_acc: 0.7836\n",
      "Epoch 475/500\n",
      "534/534 - 0s - loss: 0.3389 - acc: 0.8596 - val_loss: 0.5851 - val_acc: 0.7910\n",
      "Epoch 476/500\n",
      "534/534 - 0s - loss: 0.3229 - acc: 0.8708 - val_loss: 0.5505 - val_acc: 0.7836\n",
      "Epoch 477/500\n",
      "534/534 - 0s - loss: 0.3175 - acc: 0.8652 - val_loss: 0.5370 - val_acc: 0.7761\n",
      "Epoch 478/500\n",
      "534/534 - 0s - loss: 0.3170 - acc: 0.8633 - val_loss: 0.5261 - val_acc: 0.7463\n",
      "Epoch 479/500\n",
      "534/534 - 0s - loss: 0.3206 - acc: 0.8727 - val_loss: 0.5505 - val_acc: 0.7836\n",
      "Epoch 480/500\n",
      "534/534 - 0s - loss: 0.3161 - acc: 0.8614 - val_loss: 0.5517 - val_acc: 0.7836\n",
      "Epoch 481/500\n",
      "534/534 - 0s - loss: 0.3126 - acc: 0.8633 - val_loss: 0.5380 - val_acc: 0.7761\n",
      "Epoch 482/500\n",
      "534/534 - 0s - loss: 0.3131 - acc: 0.8670 - val_loss: 0.5511 - val_acc: 0.7836\n",
      "Epoch 483/500\n",
      "534/534 - 0s - loss: 0.3153 - acc: 0.8689 - val_loss: 0.5335 - val_acc: 0.7537\n",
      "Epoch 484/500\n",
      "534/534 - 0s - loss: 0.3267 - acc: 0.8689 - val_loss: 0.5367 - val_acc: 0.7463\n",
      "Epoch 485/500\n",
      "534/534 - 0s - loss: 0.3317 - acc: 0.8633 - val_loss: 0.5279 - val_acc: 0.7910\n",
      "Epoch 486/500\n",
      "534/534 - 0s - loss: 0.3516 - acc: 0.8446 - val_loss: 0.5430 - val_acc: 0.7612\n",
      "Epoch 487/500\n",
      "534/534 - 0s - loss: 0.3131 - acc: 0.8670 - val_loss: 0.5513 - val_acc: 0.7761\n",
      "Epoch 488/500\n",
      "534/534 - 0s - loss: 0.3120 - acc: 0.8689 - val_loss: 0.5466 - val_acc: 0.7687\n",
      "Epoch 489/500\n",
      "534/534 - 0s - loss: 0.3135 - acc: 0.8652 - val_loss: 0.5593 - val_acc: 0.7836\n",
      "Epoch 490/500\n",
      "534/534 - 0s - loss: 0.3184 - acc: 0.8614 - val_loss: 0.5258 - val_acc: 0.7910\n",
      "Epoch 491/500\n",
      "534/534 - 0s - loss: 0.3242 - acc: 0.8596 - val_loss: 0.5417 - val_acc: 0.7687\n",
      "Epoch 492/500\n",
      "534/534 - 0s - loss: 0.3114 - acc: 0.8670 - val_loss: 0.5883 - val_acc: 0.7985\n",
      "Epoch 493/500\n",
      "534/534 - 0s - loss: 0.3163 - acc: 0.8689 - val_loss: 0.5681 - val_acc: 0.7910\n",
      "Epoch 494/500\n",
      "534/534 - 0s - loss: 0.3111 - acc: 0.8689 - val_loss: 0.5484 - val_acc: 0.7687\n",
      "Epoch 495/500\n",
      "534/534 - 0s - loss: 0.3136 - acc: 0.8689 - val_loss: 0.6803 - val_acc: 0.7761\n",
      "Epoch 496/500\n",
      "534/534 - 0s - loss: 0.3419 - acc: 0.8483 - val_loss: 0.6034 - val_acc: 0.7836\n",
      "Epoch 497/500\n",
      "534/534 - 0s - loss: 0.3426 - acc: 0.8502 - val_loss: 0.6453 - val_acc: 0.7537\n",
      "Epoch 498/500\n",
      "534/534 - 0s - loss: 0.3295 - acc: 0.8614 - val_loss: 0.5871 - val_acc: 0.7910\n",
      "Epoch 499/500\n",
      "534/534 - 0s - loss: 0.3178 - acc: 0.8689 - val_loss: 0.6015 - val_acc: 0.7537\n",
      "Epoch 500/500\n",
      "534/534 - 0s - loss: 0.3284 - acc: 0.8689 - val_loss: 0.6463 - val_acc: 0.7761\n"
     ]
    }
   ],
   "source": [
    "history= model.fit(train1_x,train1_y,verbose=2,shuffle=True,nb_epoch=num_epochs,batch_size=num_batch,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223/223 - 0s - loss: 0.5684 - acc: 0.8027\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5683555758052877, 0.80269057]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_error_rate = model.evaluate(test1_x, test1_y, verbose=2)\n",
    "test_error_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperopt_gb_score(params):\n",
    "    clf = GradientBoostingClassifier(**params)\n",
    "    current_score = cross_val_score(clf, train, target, cv=10).mean()\n",
    "    print(current_score, params)\n",
    "    return current_score \n",
    " \n",
    "space_gb = {\n",
    "            'n_estimators': 500,\n",
    "            'max_depth': 5           \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "91.17"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gradient Boosting Classifier\n",
    "\n",
    "gradient_boosting = GradientBoostingClassifier()\n",
    "gradient_boosting.fit(train1_x, train1_y)\n",
    "Y_pred = gradient_boosting.predict(test1_x).astype(int)\n",
    "gradient_boosting.score(train1_x, train1_y)\n",
    "acc_gradient_boosting = round(gradient_boosting.score(train1_x, train1_y) * 100, 2)\n",
    "acc_gradient_boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "90.57"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC()\n",
    "svc.fit(train1_x, train1_y)\n",
    "Y_pred = svc.predict(test1_x).astype(int)\n",
    "acc_svc = round(svc.score(train1_x, train1_y) * 100, 2)\n",
    "acc_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "65.12"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stochastic Gradient Descent\n",
    "\n",
    "sgd = SGDClassifier()\n",
    "sgd.fit(train1_x, train1_y)\n",
    "Y_pred = sgd.predict(test1_x).astype(int)\n",
    "acc_sgd = round(sgd.score(train1_x, train1_y) * 100, 2)\n",
    "acc_sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_exp(X, Y):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(200, activation='relu', input_dim=train1_x.shape[1]))\n",
    "    model.add(Dense(200, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    \n",
    "    gradient_boosting = GradientBoostingClassifier()\n",
    "    # Compile model\n",
    "    model.compile(optimizer = gradient_boosting.fit(X, Y),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    #nadam\n",
    "    #test\n",
    "    #history= model.fit(X, Y,verbose=2,shuffle=True,nb_epoch=num_epochs,batch_size=num_batch,validation_split=0.2)\n",
    "    \n",
    "    #Y_pred = gradient_boosting.predict(X).astype(int)\n",
    "    #test_error_rate = model.evaluate(test1_x, Y_pred, verbose=2)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "('Could not interpret optimizer identifier:', GradientBoostingClassifier(criterion='friedman_mse', init=None,\n              learning_rate=0.1, loss='deviance', max_depth=3,\n              max_features=None, max_leaf_nodes=None,\n              min_impurity_decrease=0.0, min_impurity_split=None,\n              min_samples_leaf=1, min_samples_split=2,\n              min_weight_fraction_leaf=0.0, n_estimators=100,\n              n_iter_no_change=None, presort='auto', random_state=None,\n              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n              verbose=0, warm_start=False))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-1360cc680a7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#history= model.fit(train1_x, train1_y,verbose=2,shuffle=True,nb_epoch=num_epochs,batch_size=num_batch,validation_split=0.2)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#gradient_boosting.fit(train1_x, train1_y)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mcreate_exp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain1_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain1_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-61-166e8ac37310>\u001b[0m in \u001b[0;36mcreate_exp\u001b[1;34m(X, Y)\u001b[0m\n\u001b[0;32m     10\u001b[0m     model.compile(optimizer = gradient_boosting.fit(X, Y),\n\u001b[0;32m     11\u001b[0m               \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m               metrics=['accuracy'])\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[1;31m#nadam\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;31m#test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mcompile\u001b[1;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, distribute, **kwargs)\u001b[0m\n\u001b[0;32m    258\u001b[0m                                                            \u001b[0mtarget_tensors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m                                                            weighted_metrics)\n\u001b[1;32m--> 260\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m     \u001b[1;31m# We've disabled automatic dependency tracking for this method, but do want\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m     \u001b[1;31m# to add a checkpoint dependency on the optimizer if it's trackable.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\optimizers.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(identifier)\u001b[0m\n\u001b[0;32m    846\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    847\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 848\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Could not interpret optimizer identifier:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midentifier\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: ('Could not interpret optimizer identifier:', GradientBoostingClassifier(criterion='friedman_mse', init=None,\n              learning_rate=0.1, loss='deviance', max_depth=3,\n              max_features=None, max_leaf_nodes=None,\n              min_impurity_decrease=0.0, min_impurity_split=None,\n              min_samples_leaf=1, min_samples_split=2,\n              min_weight_fraction_leaf=0.0, n_estimators=100,\n              n_iter_no_change=None, presort='auto', random_state=None,\n              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n              verbose=0, warm_start=False))"
     ]
    }
   ],
   "source": [
    "#history= model.fit(train1_x, train1_y,verbose=2,shuffle=True,nb_epoch=num_epochs,batch_size=num_batch,validation_split=0.2)\n",
    "#gradient_boosting.fit(train1_x, train1_y)\n",
    "model= create_exp(train1_x, train1_y)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
